%%%%%%%%%%%%%%%%%%%%%%%%%
%% RESEARCH OBJECTIVES %%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Research Objectives}

This thesis aims to develop and validate methodologies for detecting when neural networks are likely to fail in safety-critical applications. The research addresses five primary objectives:

\begin{enumerate}
\item \textbf{Distance-based Distribution Shift Detection} \\
To develop distance metrics that quantify how far test data distributions deviate from training distributions, enabling detection of when neural networks are likely to fail.

\item \textbf{Cross-architectural Validation on Standard Datasets} \\
To validate distance-based detection methods across neural network architectures (CNN, ViT, VLM) using established computer vision datasets (MNIST, CIFAR-10).

\item \textbf{Accuracy Degradation Characterisation} \\
To characterise neural network accuracy degradation under noise and out-of-distribution conditions, establishing safe prediction thresholds based on distance metrics.

\item \textbf{Synthetic Dataset Creation for Autonomous Driving} \\
To create synthetic datasets for self-driving car applications using realistic game-engine simulation environments, providing controlled experimental conditions for safety validation.

\item \textbf{Autonomous Driving Safety Application} \\
To apply distance-based detection methodology to autonomous driving systems, demonstrating practical failure prediction in realistic simulation scenarios.
\end{enumerate}

These objectives collectively establish a framework for proactive safety assessment in autonomous systems, focusing on failure detection rather than system hardening.

Elements of this research have been peer-reviewed and published at the CGVC 2025 proceedings \cite{sikar2024misclassificationlikelihoodmatrixclasses}, with additional work accepted for presentation at the LOD 2025 \cite{sikar2025explorationssoftmaxspaceknowing} conference and inclusion in the Nature - Springer LNCS Proceedings.