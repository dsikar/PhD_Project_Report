%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% INTRODUCTION AND OBJECTIVES %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%This chapter should set the scene for the reader. It must outline the background to the problem, give your reasons for the choice of project, and identify the project’s beneficiaries. Your objectives need to be precisely stated, together with the tests that will show, at the end of the project, that they have been met (or not been met). You need also to outline your methods in broad terms, along with y work plan with sufficient detail to show how you planned to meet the objectives. Outline any major changes of goals or methods that happened during the project. Finally, outline the structure of the report, showing how it fits together.

\chapter{Introduction and Objectives}
\label{Intro} 

%%%%%%%%%%%%%%%%
% INTRODUCTION %
%%%%%%%%%%%%%%%%

\section{Introduction}


This study is sponsored by ICRI-SAVe, the Intel Collaborative Research Institute (ICRI) on Safe Automated Vehicles (SAVe), focused on practical innovations that advance the state of the art, security and resilience of real-world autonomous systems such as autonomous vehicles (AVs). Trust is a major bottleneck for commercial introduction of AVs. Consumers must feel comfortable with, and regulators need to build and approve methodologies to prove the safety of, AVs ({ICRI-SAVe2024}. This study aims to contribute in the assessment and quantification of Autonomous Systems Safety, of which AVs are a particular case.


\subsection{ICRI-SAVe}

% 1. Elaborate on ICRI-SAVe:
%    Provide more details about the institute, its mission, and its significance in the field of autonomous systems research. You could mention any notable achievements or ongoing projects.

The ICRI-SAVe project - Intel Collaborative Research Institute on Safety of Autonomous Vehicles (\cite{ICRI-SAVe2024}) , funded by Intel Corporation with a budget of USD 300,000, was officially conducted from September 2019 to September 2022. This research initiative, led by the Centre for Software Reliability at City, University of London, focused on enhancing the safety of autonomous vehicles (AVs). The project's primary objectives were to develop structured assurance cases using Assurance 2.0, employ statistical inference methods for safety confidence, and create probabilistic models to analyze the impact of road hazards and subsystem reliability on AV safety.

The research was divided into three main themes: assurance cases, diversity and defense-in-depth, and systemic risk modeling. The assurance cases aimed to clarify the reasoning from evidence to top-level safety claims, utilizing the "claims, argument, evidence (CAE)" framework. Probabilistic modeling techniques, including stochastic activity networks and Markov models, were used to study the imperfections in perception systems and safety monitors. The project also focused on mathematical models combining Bayesian reasoning and bounding methods to address uncertainties from various evidence sources.

The project's achievements include contributions to understanding the role of diversity in AV safety and developing robust models for safety assurance. The project involved collaboration with research institutions such as Karlsruhe Institute of Technology and Fraunhofer IESE, enhancing its impact on the field of autonomous systems safety research.

% 2. Expand on the concept of trust in AVs:
%    Discuss the various aspects of trust, such as reliability, safety, security, and ethical decision-making. You could mention specific concerns that consumers and regulators have regarding AVs.

\subsection{Trust in Autonomous Vehicles}

Trust in Autonomous Vehicles (AVs) encompasses several critical aspects such as reliability, safety, security, and ethical decision-making. For AVs to be widely accepted and integrated into everyday life, it is essential to address these concerns comprehensively. This section discusses these various aspects and highlights specific concerns that consumers and regulators have regarding AVs.

\textbf{Reliability} refers to the consistent performance of AVs under various conditions. For consumers, the reliability of AVs is paramount as it determines the vehicle's dependability in routine operations and unexpected scenarios. Issues such as software bugs, hardware malfunctions, or failures in sensor systems can significantly undermine trust. Studies indicate that consumers are particularly wary of AVs' ability to handle adverse weather conditions or complex traffic situations (\cite{gogoll2017}).

\textbf{Safety} is the most significant factor influencing trust in AVs. This aspect covers the vehicle's ability to avoid accidents and protect passengers and pedestrians. According to the National Highway Traffic Safety Administration (NHTSA), while AVs have the potential to reduce accidents caused by human error, there is a need for rigorous testing and validation to ensure their safety in real-world conditions (\cite{nhtsa2020}). Incidents involving AVs, such as the fatal Uber crash in 2018, have heightened public concern and skepticism about the technology’s readiness (\cite{goodall2016}).

\textbf{Security} concerns involve the protection of AVs from cyber-attacks. As AVs rely heavily on software and connectivity for their operation, they are vulnerable to hacking, which could lead to disastrous consequences. Ensuring robust cybersecurity measures is essential to protect against unauthorized access and data breaches. The European Union Agency for Cybersecurity (ENISA) has emphasized the importance of cybersecurity in AVs, recommending the implementation of stringent security protocols and regular updates to counter emerging threats (\cite{enisa2020}).

\textbf{Ethical decision-making} in AVs involves programming these vehicles to make decisions during unavoidable accidents. This aspect raises moral and philosophical questions about how AVs should prioritize lives and property in critical situations. The "trolley problem" is a classic example often discussed in the context of AV ethics, where the vehicle must choose between two harmful outcomes (\cite{lin2016}). Public trust in AVs significantly depends on transparent and ethically sound decision-making frameworks that align with societal values.

Consumers are primarily concerned with the aforementioned aspects of trust—reliability, safety, security, and ethical decision-making. Additionally, there is apprehension about the lack of control and the ability to intervene in the vehicle’s operation during emergencies. Regulators, on the other hand, focus on establishing comprehensive guidelines and standards to ensure the safe deployment of AVs. They are concerned with liability issues, the adequacy of current infrastructure to support AV technology, and the long-term societal impacts of widespread AV adoption (\cite{litman2020}).

Building trust in AVs is a complex endeavor that requires addressing reliability, safety, security, and ethical decision-making comprehensively. Both consumer acceptance and regulatory approval hinge on demonstrating that AVs can operate dependably and safely while adhering to ethical standards. Ongoing research, transparent communication, and robust regulatory frameworks are crucial to fostering trust in this transformative technology.

% 3. Discuss the current state of AV technology:
%    Provide a brief overview of where AV technology stands today, including major players in the field and recent advancements.

\subsection{Current State of AV Technology}

Autonomous Vehicle (AV) technology has evolved significantly in the past decade, moving from conceptual designs to real-world deployments. Major technology companies and traditional automakers are investing heavily in this field, leading to a diverse and competitive landscape.

Currently, most commercially available autonomous systems operate at SAE Level 2 or Level 3 autonomy (\cite{SAE2021}). These systems can control steering, acceleration, and braking in specific scenarios but require human oversight. However, several companies are actively testing Level 4 and Level 5 systems, which promise full autonomy in most or all driving conditions (\cite{Yurtsever2020}).

Waymo, a subsidiary of Alphabet Inc., is one of the leaders in the AV field. Their self-driving taxi service, Waymo One, has been operational in Phoenix, Arizona since 2018, recently expanding to San Francisco (\cite{Waymo2023}). Tesla, with its Autopilot and Full Self-Driving (FSD) systems, has the largest fleet of AVs, providing vast amounts of real-world data (\cite{Tesla2023}).

Other major players include traditional automakers like General Motors (through its Cruise subsidiary), Ford, and Volkswagen, as well as technology companies like Uber, Aptiv, and Baidu (\cite{Koopman2019}). These companies are employing a variety of sensing technologies, including LIDAR, radar, cameras, and ultrasonic sensors, often in combination (\cite{Yurtsever2020}).

Recent advancements in the field include improved perception systems capable of detecting and classifying objects with greater accuracy, even in challenging weather conditions (\cite{Grigorescu2020}). There have also been significant developments in decision-making algorithms, with the incorporation of deep learning and reinforcement learning (\cite{Kiran2021}).

Despite these advancements, several challenges remain. These include ensuring safety in the high-numbering edge cases, sometimes referred to as "the long tail", gaining regulatory approval, addressing ethical concerns, and achieving public acceptance (\cite{Koopman2019}). The ability of AVs to operate in diverse environments and weather conditions, as well as their interaction with human-driven vehicles and pedestrians, are ongoing areas of research and development (\cite{Yurtsever2020}).

It is clear that AVs have the potential to disrupt transportation. However, the timeline for widespread adoption of fully autonomous vehicles remains uncertain and dependent on overcoming technical, regulatory, and social challenges (\cite{Litman2023}).

% 4. Elaborate on safety methodologies:
%    Explain some of the current methodologies used to assess and prove the safety of AVs, and why new or improved methods are needed.

\subsection{Safety Methodologies for Autonomous Vehicles}

The assessment and verification of safety in Autonomous Vehicles (AVs) present unique challenges that necessitate both the adaptation of traditional automotive safety practices and the development of novel methodologies. Current approaches encompass a wide range of techniques, each with its own strengths and limitations.

One prevalent methodology is scenario-based testing, where AVs are evaluated against a comprehensive set of pre-defined driving scenarios (\cite{Feng2021}). These scenarios aim to cover a broad spectrum of driving conditions, from routine situations to rare, high-risk events. However, the vast number of possible scenarios makes exhaustive testing impractical, leading to the development of methods for intelligent scenario selection and generation (\cite{Koren2018}).

Formal methods and model checking represent another critical approach in AV safety assessment. These techniques involve creating mathematical models of AV systems and their environments, then using automated tools to verify that specific safety properties are consistently maintained (\cite{Luckcuck2019}). While powerful, these methods can be computationally intensive and may struggle to fully capture the complexity of real-world driving environments.

Simulation-based testing plays a crucial role in AV safety assessment. Advanced simulators enable the testing of AVs in virtual environments, allowing for the evaluation of numerous scenarios without the risks associated with real-world testing (\cite{Dosovitskiy2017}). However, ensuring that simulations accurately represent real-world conditions remains a significant challenge.

The concept of 'safety of the intended functionality' (SOTIF) has gained prominence in recent years (\cite{ISO21448}). SOTIF focuses on ensuring that a system is safe even when all its components are functioning as intended, addressing issues such as sensor limitations or algorithmic edge cases that traditional functional safety approaches might overlook.

Despite these methodologies, there is a growing consensus that new and improved methods are needed (\cite{Koopman2019}). Several factors drive this need:

\begin{enumerate}
    \item \textbf{System Complexity}: AVs are highly complex systems operating in unpredictable environments. Traditional safety assessment methods may not adequately capture all potential failure modes or interactions (\cite{Burton2017}).
    
    \item \textbf{Machine Learning Challenges}: Many AV systems rely heavily on machine learning algorithms, particularly deep neural networks. The 'black box' nature of these algorithms makes them difficult to verify using traditional methods (\cite{Salay2019}).
    
    \item \textbf{Edge Case Identification}: Rare but critical scenarios, often called 'edge cases', are particularly challenging for AVs. Identifying and testing for all possible edge cases is an ongoing challenge (\cite{Koopman2016}).
    
    \item \textbf{Evolving Systems}: Many AV systems are designed to learn and adapt over time. Ensuring the safety of such evolving systems requires new approaches to continuous verification and validation (\cite{Seshia2016}).
    
    \item \textbf{Human-Machine Interaction}: As long as AVs share the road with human-driven vehicles and pedestrians, understanding and ensuring safe human-machine interaction is crucial (\cite{Vinkhuyzen2018}).
\end{enumerate}

Addressing these challenges requires interdisciplinary approaches combining expertise from fields such as robotics, computer science, systems engineering, and human factors. Emerging methodologies include adaptive testing frameworks, explainable AI techniques, and novel approaches to formal verification of machine learning systems (\cite{Seshia2016}).

As AV technology continues to advance, so too must our methods for ensuring their safety. The development of robust, comprehensive, and widely accepted safety assessment methodologies remains a critical challenge in the field of autonomous driving, necessitating ongoing research and innovation in this area.

% 5. Connect to broader autonomous systems:
%    Explain how AVs fit into the larger category of autonomous systems and why lessons learned from AV safety could be applicable to other domains.

\subsection{Connecting AVs to Broader Autonomous Systems}

Autonomous Vehicles (AVs) represent a prominent subset of the larger field of autonomous systems, which encompasses a wide range of self-governing machines and software designed to operate with minimal human intervention. The challenges and solutions developed for AV safety have broad implications for autonomous systems in general, offering valuable insights and methodologies that can be applied across various domains.

At their core, AVs share fundamental characteristics with other autonomous systems, including perception, decision-making, and actuation capabilities (\cite{Scharre2018}). These systems must operate reliably in complex, dynamic environments, often alongside humans, while adhering to strict safety requirements. This commonality allows for the transfer of knowledge and methodologies between AVs and other autonomous domains such as robotics, unmanned aerial vehicles (UAVs), and industrial automation systems (\cite{Kaber2018}).

One key area where AV research has potential cross-domain applications is in the development of robust perception systems. The techniques used for sensor fusion, object detection, and environmental mapping in AVs can be adapted for use in other autonomous systems operating in challenging environments (\cite{Thrun2005}). For instance, the methods developed for AVs to navigate in urban environments could inform the design of autonomous robots for disaster response or space exploration.

Similarly, the decision-making algorithms developed for AVs, particularly those dealing with uncertain and partially observable environments, have broad applicability. The use of probabilistic reasoning, reinforcement learning, and planning under uncertainty in AVs provides valuable insights for autonomous systems in fields ranging from healthcare to finance (\cite{Russell2015}).

The safety assurance methods being developed for AVs are particularly relevant to other safety-critical autonomous systems. Formal verification techniques, scenario-based testing, and safety of the intended functionality (SOTIF) approaches pioneered in the AV domain can be adapted to verify and validate other types of autonomous systems (\cite{Koopman2019}). For example, the methods used to ensure AV safety in unpredictable traffic scenarios could inform safety protocols for autonomous surgical robots or nuclear plant control systems.

Furthermore, the ethical considerations and decision-making frameworks being developed for AVs in scenarios involving potential harm have implications for autonomous systems in various fields. The trolley problem and its variants, often discussed in the context of AVs, are relevant to any autonomous system that must make decisions with potential ethical implications (\cite{Awad2018}).

The regulatory frameworks and standards being developed for AVs also provide a template for governance of other autonomous systems. The approaches to certification, testing, and ongoing monitoring of AVs can inform regulatory strategies for other autonomous technologies (\cite{Cummings2021}).

However, it's important to note that while there are many commonalities, each domain of autonomous systems also has unique challenges. The specific operational environment, risk profile, and societal impact of different autonomous systems may necessitate tailored approaches (\cite{Endsley2017}). For instance, while an AV primarily interacts with its environment through physical movement, an autonomous trading system interacts through financial transactions, requiring different safety and ethical considerations.

In conclusion, the lessons learned from AV safety research and development offer valuable insights for the broader field of autonomous systems. By leveraging these insights and adapting them to specific domains, we can accelerate the development of safe and reliable autonomous systems across a wide range of applications. As research in AVs continues to advance, it will likely remain a key driver of innovation in the larger autonomous systems landscape.

% 6. Highlight the challenges in quantifying safety:
%    Discuss why quantifying the safety of autonomous systems is complex and why it's crucial for their widespread adoption.

\subsection{Challenges in Quantifying Safety of Autonomous Systems}

Quantifying the safety of autonomous systems, particularly Autonomous Vehicles (AVs), presents a challenge that is crucial to overcome for widespread adoption. The difficulty lies in the nature of safety in these systems and the limitations of traditional safety metrics when applied to autonomy.

One fundamental challenge is the sheer complexity of the operational environment. Autonomous systems must navigate through an almost infinite number of possible scenarios, many of which may be difficult to anticipate or model (\cite{Koopman2016}). This 'open world' problem makes it challenging to define a comprehensive set of safety criteria that covers all potential situations.

Traditional automotive safety metrics, such as the number of accidents per million miles driven, are insufficient for autonomous systems. These metrics fail to capture the nuanced performance of AI-driven systems and don't account for the quality or difficulty of the miles driven (\cite{Kalra2016}). Moreover, rare but critical events, often termed 'edge cases', are particularly problematic for statistical approaches to safety quantification (\cite{Koopman2019}).

The probabilistic nature of accidents poses a significant challenge. Unlike traditional engineering systems, where failures can often be traced to specific components or design flaws, accidents involving AVs can result from a complex interplay of factors, including human error, environmental conditions, and unforeseen interactions with other road users. This makes it difficult to predict and quantify the likelihood of accidents with high confidence (\cite{Zhao2020}).

Moreover, the behavior of autonomous systems is often non-deterministic, especially when machine learning algorithms are involved. These algorithms can make decisions based on patterns in data that may not be explicitly programmed. As a result, predicting and verifying the behavior of such systems in every possible situation becomes challenging (\cite{Amodei2016}).

The use of machine learning algorithms, particularly deep learning, in autonomous systems introduces additional complexities in safety quantification. These systems often behave as 'black boxes', making it difficult to provide formal guarantees about their behaviour or to fully understand their decision-making processes (\cite{Burton2017}). This lack of interpretability poses significant challenges for safety certification and public trust.

Another key challenge is the dynamic nature of autonomous systems. Many of these systems, including AVs, are designed to learn and adapt over time. This continuous evolution makes it difficult to apply traditional safety assessment methods, which often assume a static system (\cite{Salay2019}). Ensuring that safety is maintained as the system learns and adapts is a significant challenge.

The interaction between autonomous systems and humans adds another layer of complexity to safety quantification. In semi-autonomous systems or in environments where autonomous systems operate alongside humans, the variability and unpredictability of human behaviour must be accounted for in safety assessments (\cite{Endsley2017}). This human-machine interaction is particularly challenging to model and quantify.

Despite these challenges, quantifying safety is crucial for the widespread adoption of autonomous systems. Clear, quantifiable safety metrics are necessary for several reasons:

1. Regulatory Compliance: Regulators require concrete evidence of safety before allowing autonomous systems to operate in public spaces (\cite{Cummings2021}).

2. Public Trust: Quantifiable safety metrics can help build public confidence in autonomous systems, which is essential for their acceptance and adoption (\cite{Choi2020}).

3. Design and Development: Clear safety metrics provide goals and benchmarks for system designers and developers, guiding the improvement of autonomous systems (\cite{Shalev2017}).

4. Insurance and Liability: Quantifiable safety metrics are necessary for insurance companies to assess risk and for determining liability in case of accidents (\cite{Schellekens2015}).

5. Ethical Considerations: Quantifiable safety metrics can inform ethical decision-making processes in the development and deployment of autonomous systems (\cite{Awad2018}).

Addressing these challenges requires interdisciplinary approaches combining expertise from fields such as robotics, statistics, psychology, and ethics. New methodologies being explored include adaptive testing frameworks, formal verification of machine learning systems, and novel approaches to scenario generation and analysis (\cite{Seshia2016}).

% 7. Mention regulatory landscape:
%    Briefly touch upon the current regulatory environment for AVs and autonomous systems in different regions.

\subsection{Regulatory Landscape for Autonomous Vehicles and Systems}

The regulatory environment for Autonomous Vehicles (AVs) and other autonomous systems is evolving rapidly, with different regions adopting varied approaches. This diversity in regulation reflects the complex challenges of balancing innovation, safety, and public interest in the face of rapidly advancing technology.

In the United States, the regulatory approach has been largely decentralized, with individual states taking the lead in AV regulation (\cite{Claybrook2018}). The National Highway Traffic Safety Administration (NHTSA) has provided guidelines for AV testing and deployment, but these are largely voluntary (\cite{nhtsa2020}). This flexible approach has facilitated extensive AV testing, but it has also led to a patchwork of regulations that may complicate interstate operations.

The European Union has taken a more centralized approach, working towards harmonized regulations across member states. The EU has introduced the AV-Ready initiative, aiming to create a comprehensive regulatory framework for AVs (\cite{EuropeanCommission2020}). This includes updates to type-approval regulations and efforts to address liability and ethical issues.

In Asia, countries like China, Japan, and Singapore have been proactive in creating regulatory frameworks for AVs. China, in particular, has implemented national guidelines for AV testing and is working on standards for AV deployment (\cite{Du2020}). Singapore has created a flexible regulatory framework that allows for rapid adaptation to technological advancements (\cite{Taeihagh2019}).

Globally, there's a growing recognition of the need for international cooperation in AV regulation. The United Nations Economic Commission for Europe (UNECE) has been working on amendments to the Vienna Convention on Road Traffic to accommodate AVs (\cite{UNECE2021}).

For broader autonomous systems, regulatory approaches vary significantly depending on the application domain. In aviation, for instance, regulations for autonomous drones are more developed than those for autonomous passenger aircraft (\cite{Hodgkinson2018}). In healthcare, regulatory bodies like the FDA in the US are developing frameworks for AI and machine learning in medical devices (\cite{FDA2021}).

A key challenge across all regions is keeping pace with rapid technological advancements. Regulators are increasingly adopting "adaptive" or "agile" regulatory approaches that allow for more flexibility and rapid updates (\cite{Eggers2019}). These approaches aim to balance the need for safety and accountability with the desire to foster innovation.

Another common theme is the shift towards performance-based regulations rather than prescriptive rules. This approach focuses on defining desired outcomes rather than specifying exact methods, allowing for technological innovation while maintaining safety standards (\cite{Cihon2019}).

Ethics and liability remain challenging areas for regulators globally. Questions about how to encode ethical decision-making into autonomous systems and how to assign liability in case of accidents are still largely unresolved (\cite{Awad2018}).

As the technology continues to evolve, regulatory frameworks will need to adapt. The challenge for policymakers will be to create regulations that ensure safety and public trust while allowing for continued innovation in the field of autonomous systems.

% 8. Discuss societal impact:
%    Expand on how the introduction of AVs and other autonomous systems could impact society, including potential benefits and concerns.

\subsection{Societal Impact of Autonomous Vehicles and Systems}

The introduction of Autonomous Vehicles (AVs) and other autonomous systems is poised to bring about profound changes to society, offering a mix of potential benefits and concerns that warrant careful consideration.

One of the most frequently cited benefits of AVs is the potential for significantly improved road safety. With human error contributing to the vast majority of traffic accidents, AVs could dramatically reduce road fatalities and injuries (\cite{Fagnant2015}). This could lead to substantial societal benefits in terms of lives saved, reduced healthcare costs, and improved quality of life for many.

AVs also promise enhanced mobility for those who are unable to drive conventional vehicles, such as the elderly, disabled, or young people. This increased independence could have far-reaching effects on social inclusion and quality of life for these groups (\cite{Harper2016}). Furthermore, the potential for more efficient traffic flow and reduced congestion could lead to time savings and increased productivity for commuters (\cite{Wadud2016}).

From an environmental perspective, AVs could contribute to reduced emissions and energy consumption through more efficient driving patterns and the potential for increased use of electric vehicles (\cite{Greenblatt2015}). However, this benefit could be offset if AVs lead to increased vehicle usage overall.

The economic impact of AVs and autonomous systems is likely to be substantial. While they may create new job opportunities in technology and related fields, there are concerns about job displacement, particularly in transportation-related industries (\cite{Autor2015}). The trucking and taxi industries, for instance, could face significant disruption.

Urban planning and infrastructure could also see major changes. AVs might reduce the need for parking spaces in city centres, potentially freeing up valuable urban land for other uses (\cite{Duarte2018}). However, they might also encourage urban sprawl by making longer commutes more tolerable.

Privacy and data security represent significant concerns as AVs and other autonomous systems collect and process vast amounts of data. Questions about who owns this data, how it's used, and how it's protected are crucial ethical and legal issues that society will need to address (\cite{Taeihagh2019}).

The introduction of autonomous systems also raises complex ethical questions. For AVs, the much-discussed "trolley problem" highlights the challenges of encoding ethical decision-making into autonomous systems (\cite{Awad2018}). Similar ethical dilemmas exist for other autonomous systems, such as AI in healthcare or autonomous weapons systems.

There are also concerns about the potential for AVs and other autonomous systems to exacerbate existing social inequalities. If these technologies are not equitably distributed, they could create or widen gaps in mobility, job opportunities, and quality of life between different socioeconomic groups (\cite{Milakis2017}).

The psychological impact of increased automation in daily life is another area of consideration. While autonomous systems may reduce stress in some areas (e.g., driving in heavy traffic), they may also lead to a sense of loss of control or purpose for some individuals (\cite{Hancock2020}).

In the broader context of autonomous systems, the impact on work and employment is a critical consideration. While automation may eliminate certain jobs, it also has the potential to augment human capabilities, creating new types of jobs and potentially leading to more fulfilling work by eliminating routine tasks (\cite{Autor2015}).

Education systems will likely need to adapt to prepare people for a world where interaction with autonomous systems is commonplace. This may involve changes in curriculum to emphasise skills that complement rather than compete with AI and autonomous systems (\cite{Manyika2017}).

The introduction of autonomous systems, is having, and may have even more, profound effects on human behaviour and social norms. For instance, AVs could change our relationship with car ownership, potentially leading to more shared mobility models (\cite{Fagnant2015}). Similarly, other autonomous systems might alter our expectations around service delivery, decision-making processes, and human-machine interactions.

While AVs and other autonomous systems offer numerous potential benefits to society, their introduction also raises significant challenges and concerns. Addressing these issues will require ongoing dialogue between technologists, policymakers, ethicists, and other groups to ensure that the development and deployment of these technologies aligns with societal values and goals.

% 10. Interdisciplinary nature:
%     Highlight how this research combines elements from various fields such as computer science, engineering, psychology, and policy-making.

\subsection{Interdisciplinary Nature of Autonomous Systems Research}

The development and implementation of autonomous systems, particularly Autonomous Vehicles (AVs), is inherently interdisciplinary, drawing on expertise from a wide range of fields. This convergence of disciplines is not only necessary but crucial for addressing the complex challenges posed by autonomous systems.

At its core, autonomous systems research is deeply rooted in computer science and engineering. The development of sensing technologies, machine learning algorithms, and control systems forms the technical foundation of AVs (\cite{Yurtsever2020}). Computer vision, a key component in AV perception systems, combines elements of computer science, mathematics, and cognitive science (\cite{Grigorescu2020}). Similarly, the creation of robust decision-making algorithms draws on artificial intelligence, operations research, and control theory (\cite{Kiran2021}).

However, the scope of AV research extends far beyond these technical domains. The field of human factors and ergonomics plays a crucial role in designing user interfaces and understanding human-machine interaction in semi-autonomous systems (\cite{Endsley2017}). This intersection of engineering and psychology is vital for ensuring that autonomous systems can safely and effectively collaborate with human operators and other road users.

Ethical considerations in autonomous systems necessitate input from philosophy and applied ethics. The much-discussed 'trolley problem' in the context of AVs, for instance, has sparked collaboration between engineers, ethicists, and psychologists to understand how ethical decision-making can be encoded into autonomous systems (\cite{Awad2018}). This ethical dimension also extends to considerations of fairness and bias in AI systems, drawing on social sciences and legal studies.

The legal and regulatory aspects of autonomous systems involve a synthesis of technical knowledge with law and policy studies. Policymakers must work closely with technologists to create appropriate regulatory frameworks that ensure safety while fostering innovation (\cite{Cummings2021}). This collaboration is essential for addressing complex issues such as liability in accidents involving autonomous systems.

Urban planning and transportation engineering are also integral to AV research, as the widespread adoption of AVs could significantly impact city layouts and transportation systems (\cite{Duarte2018}). This necessitates collaboration between technologists, urban planners, and civil engineers to anticipate and shape the future of urban mobility.

The economic implications of autonomous systems, including potential job displacement and new business models, require input from economists and business strategists (\cite{Autor2015}). Understanding and predicting these economic impacts is crucial for policymaking and societal preparation for widespread autonomous system adoption.

Environmental science also plays a role, particularly in assessing the potential environmental impacts of AVs, such as changes in energy consumption and emissions (\cite{Greenblatt2015}). This involves collaboration between environmental scientists, engineers, and policymakers to ensure that autonomous systems contribute to sustainability goals.

The cybersecurity aspects of autonomous systems necessitate expertise from computer security specialists, cryptographers, and network engineers (\cite{Loukas2018}). Ensuring the security and resilience of autonomous systems against potential cyber attacks is crucial for their safe deployment.

Finally, the social and psychological impacts of increasing automation in daily life are being studied by sociologists and psychologists (\cite{Hancock2020}). Understanding public perception, trust, and acceptance of autonomous systems is crucial for their successful integration into society.

This interdisciplinary approach to autonomous systems research is not without challenges. Different disciplines often have distinct methodologies, terminologies, and priorities, which can lead to communication difficulties and conflicting objectives (\cite{Stilgoe2018}). However, these challenges also present opportunities for innovation and holistic problem-solving.

In conclusion, the development of autonomous systems, particularly AVs, is a prime example of how complex technological challenges require interdisciplinary solutions. By bringing together expertise from diverse fields, researchers can address not only the technical aspects of autonomous systems but also their wider implications for society, ethics, and policy. This holistic approach is essential for realising the potential benefits of autonomous systems while mitigating potential risks and negative impacts.

% 9. Outline specific research goals:
%    Provide more details about what aspects of autonomous system safety the study aims to address and how it plans to contribute to the field.

\subsection{Additional notes on ICRI-SAVe}

% from https://x.com/i/grok?conversation=1924851698293493877

Key Points

    The ICRI-SAVe project focused on ensuring autonomous vehicle safety through research from 2019 to 2022.
    It was led by Professor Robin Bloomfield at City, University of London, funded by Intel with \$300,000.
    Research suggests it developed methods like assurance cases and Bayesian modeling for safety.
    The evidence leans toward significant contributions to AV safety, with publications like safety case templates.

Project Overview
The ICRI-SAVe project, or Intel Collaborative Research Institute on Safety of Autonomous Vehicles, was a three-year research initiative running from September 2019 to September 2022. Funded by Intel with a budget of \$300,000, it aimed to enhance the safety of autonomous vehicles (AVs) through collaborative research.
Leadership and Collaboration
The project was led by Professor Robin Bloomfield at City, University of London, with key contributors including Professor Lorenzo Strigini, Dr Peter Popov, and Professor Artur Garcez. It involved collaboration with institutions like Karlsruhe Institute of Technology and Fraunhofer IESE, fostering a multidisciplinary approach.
Research Focus
The project focused on developing advanced safety assurance methods, including:

    Structuring assurance cases using Assurance 2.0.
    Statistical inference with Bayesian approaches for safety confidence.
    Probabilistic modeling to analyze road hazards and subsystem reliability.
    Exploring diversity's role in enhancing AV safety.

Techniques used included the Claims, Argument, Evidence (CAE) framework, Bayesian reasoning, and Markov models, aiming to address complex safety challenges in AVs.
Survey Note: Detailed Analysis of the ICRI-SAVe Project
The ICRI-SAVe project, formally known as the Intel Collaborative Research Institute on Safety of Autonomous Vehicles, represents a significant effort in the domain of autonomous vehicle (AV) safety research. This initiative, spanning from September 2019 to September 2022, was funded by Intel Corporation with a budget of \$300,000, highlighting Intel's commitment to advancing safety in emerging transportation technologies. Below, we provide a comprehensive examination of the project's scope, objectives, methodologies, outcomes, and broader implications, drawing from available online resources and academic publications.
Project Background and Funding
Initiated in September 2019, the ICRI-SAVe project concluded in September 2022, aligning with a period of rapid development in autonomous vehicle technologies. The funding, amounting to \$300,000, was provided by Intel Corporation, USA, underscoring the corporate interest in ensuring the safety and reliability of AVs as they transition toward widespread deployment. This financial support facilitated collaboration between industry and academia, a model increasingly vital for addressing complex technological challenges.
Leadership and Institutional Collaboration
The project was led by Professor Robin Bloomfield at the Centre for Software Reliability, City, University of London. Key co-investigators included Professor Lorenzo Strigini, Dr Peter Popov, and Professor Artur Garcez, with additional researchers such as Professor Peter Bishop, Dr Andrey Povyakalo, Dr Kizito Salako, Ms Robab Aghazadeh Chakherlou, Mr Mathew Stewart, Mr Daniel Matvienko-Sikar, and Dr Francesco Terrosi. This team was supported by a network of collaborators, including:

    Karlsruhe Institute of Technology (Germany)
    FZI Research Center for Information Technology (Germany)
    Fortiss GmbH (Germany)
    Technical University of Munich (Germany)
    Fraunhofer IESE (Germany)

This collaborative framework ensured a multidisciplinary approach, integrating expertise from software reliability, safety engineering, and probabilistic modeling.
Objectives and Research Focus
The ICRI-SAVe project was designed to address critical safety challenges in autonomous vehicles, with the following primary objectives:

    Structuring Assurance Cases: The project aimed to enhance the semantics of assurance cases using Assurance 2.0, a framework for structuring arguments to demonstrate safety compliance. This involved developing structured claims, arguments, and evidence (CAE) to ensure robust safety arguments.
    Statistical Inference for Safety Confidence: It employed statistical inference methods, particularly a Bayesian approach, to support confidence in AV safety. This involved integrating evidence from simulated or real operations to quantify safety levels, addressing the challenge of limited empirical data in early AV deployment.
    Probabilistic Modeling of Vehicle Safety: The research included probabilistic modeling to analyze the impact of road hazards in various scenarios and the reliability of subsystems such as perception systems and safety monitors. Techniques like stochastic activity networks (SAN) and Markov and semi-Markov models were utilized to model system behavior under uncertainty.
    Analysis of Diversity's Role in Safety: The project explored how diversity in system design, such as redundant subsystems or diverse algorithms, could enhance safety, particularly in mitigating common-mode failures in AVs.

These objectives were underpinned by themes such as assurance cases, diversity and defense-in-depth, and systemic risk modeling, reflecting a holistic approach to AV safety.
Methodologies and Techniques
The research leveraged a suite of advanced methodologies to achieve its objectives, as detailed in the following table:
Technique
	
Description
Claims, Argument, Evidence (CAE) Framework
	
Structured approach to build safety cases, linking claims to evidence through arguments.
Bayesian Reasoning
	
Statistical method for updating safety confidence based on new evidence, particularly useful for AVs with limited operational data.
Bounding Methods
	
Techniques to estimate upper and lower bounds of safety risks, aiding in risk assessment.
Stochastic Activity Networks (SAN)
	
Modeling framework for analyzing system reliability and performance under stochastic conditions.
Markov and Semi-Markov Models
	
Probabilistic models for analyzing system states and transitions, crucial for safety analysis.
Justification and Verification for Machine Learning
	
Methods to ensure machine learning components in AVs are safe and reliable, addressing black-box challenges.
These techniques were applied to develop robust safety assurance strategies, particularly for AVs incorporating machine learning, which are prone to unique safety risks due to their adaptive and data-driven nature.
Outcomes and Publications
While the project's dedicated website http://icri-save.de/ is no longer accessible, evidence of its outcomes is found in academic publications and research profiles of the principal investigators. Notably:

    "Safety Case Templates for Autonomous Systems" , published in 2021, documents safety assurance argument templates for autonomous systems with machine learning components. It covers development of safety requirements, hazard analysis, safety monitor architecture, and system adaptation over time, aligning directly with the project's objectives.
    The Tigars project (Towards Identifying and closing Gaps in Assurance of autonomous Road vehicleS) produced a collection of technical notes, including parts 1 and 2, focusing on assurance overview, resilience, and safety, as seen in Professor Bloomfield's ResearchGate profile. These notes likely emerged from or were influenced by ICRI-SAVe research.
    Additional publications by Professor Bloomfield, such as works on security-informed safety and systemic risk, suggest broader contributions to AV safety, potentially overlapping with ICRI-SAVe's scope. For instance, a 2019 paper on Security-Informed Safety highlights the interplay between security and safety, relevant for AVs with connected systems.

These publications indicate that the project contributed to the academic and practical understanding of AV safety, particularly through structured assurance cases and probabilistic modeling, with potential impacts on industry standards and future research.
Broader Context and Implications
The ICRI-SAVe project is part of Intel's broader network of collaborative research institutes, such as the Intel Collaborative Research Institute for Collaborative Autonomous & Resilient Systems (ICRI-CARS), which focuses on security, privacy, and functional safety of autonomous systems. Launched in October 2019 at Intel Karlsruhe, ICRI-SAVe specialized in safe automated vehicles, complementing these efforts by focusing on safety-specific challenges. This initiative reflects the growing need for interdisciplinary collaboration to address the safety-critical nature of AVs, especially as they integrate advanced technologies like machine learning and connect via vehicle-to-everything (V2X) communications.
The project's emphasis on probabilistic modeling and diversity aligns with current industry trends, where AV safety is a debated topic due to high-profile accidents and regulatory uncertainties. Its outcomes, such as safety case templates, could inform future standards for AV deployment, potentially influencing regulatory frameworks and industry practices by 2025.
Challenges and Future Directions
Given the project's completion in 2022, its long-term impact remains an area for further study. Challenges include the scalability of assurance cases for large-scale AV deployments and the integration of machine learning safety verification into real-world systems. Future research might build on ICRI-SAVe's work to address emerging issues, such as ethical considerations in AV safety and the role of human oversight in autonomous systems.
In conclusion, the ICRI-SAVe project represents a pivotal effort in advancing the safety of autonomous vehicles through collaborative, methodologically rigorous research. Its contributions, documented in academic publications and technical reports, underscore its relevance to the ongoing development and deployment of AVs, with potential implications for safety standards and public trust in autonomous transportation systems as of May 2025.
Key Citations

    ICRI-SAVe Project Details at City University
    Professor Robin Bloomfield Research Profile
    Safety Case Templates for Autonomous Systems

% from https://gemini.google.com/app/e102b83dbb87651a

The ICRI-SAVe Project: Advancing Safety and Trust in Autonomous Vehicles1. Executive SummaryThe Intel Collaborative Research Institute on Safety of Autonomous Vehicles (ICRI-SAVe) represented a pivotal three-year research endeavor, initiated by Intel Labs, Germany, in September 2019 and concluding in September 2022.1 This initiative was strategically funded by Intel Corporation, USA, with a specific allocation of $300,000 directed towards the participating team at City, University of London.1 This funding model aligns with Intel's broader commitment to investing approximately $100 million annually into university research programs globally, fostering innovation across various technology areas.3The project was built upon a collaborative network of prominent European academic institutions, including City, University of London, Karlsruhe Institute of Technology, FZI Research Center for Information Technology, Fortis GmbH, Technical University of Munich, and Fraunhofer IESE.1 The core research of ICRI-SAVe was structured around three interconnected themes: assurance cases, diversity and defence-in-depth, and systemic risk modeling, with a pronounced emphasis on mathematical and probabilistic modeling techniques for autonomous vehicle (AV) safety.1Key contributions from ICRI-SAVe include the development of advanced methods for structuring assurance cases, leveraging frameworks like Assurance 2.0 and the Claims, Argument, Evidence (CAE) approach. The project also pioneered statistical inference techniques to bolster confidence in AV safety through Bayesian methods, alongside sophisticated probabilistic modeling of vehicle safety in diverse scenarios. Furthermore, it provided in-depth analysis of diversity's role in enhancing AV safety.1The work undertaken by ICRI-SAVe directly supports the broader industry imperative for verifiable and transparent safety frameworks. This strategic alignment is particularly notable given Intel's advocacy for models such as Responsibility-Sensitive Safety (RSS), which other Intel Collaborative Research Institutes utilize as a foundational concept for their AV safety investigations.6Intel's investment in ICRI-SAVe illustrates a deliberate approach to cultivating foundational academic research in AV safety, particularly in mathematical and probabilistic modeling. This research provides a robust scientific underpinning that can inform and validate broader Intel initiatives, such as Mobileye's RSS framework, thereby strengthening their commercial safety claims and product development efforts. The project's location in Germany and its collaboration with European institutions suggest an intentional effort to leverage specific regional academic strengths in software reliability and formal methods, which are critical for developing rigorous safety assurance cases.The emphasis within ICRI-SAVe on formal assurance cases and mathematical/probabilistic modeling signifies a crucial paradigm shift in AV safety. Rather than relying predominantly on extensive and often prohibitive road testing, the project aimed to develop methods for quantifying confidence in safety through rigorous, verifiable frameworks. This approach is fundamental for scaling AV deployment, reducing validation costs, and building public and regulatory trust by offering transparent, explainable safety arguments. It represents a move towards a more scientific, engineering-driven approach to safety certification, complementing real-world testing with provable guarantees.2. Introduction to the ICRI-SAVe ProjectThis section details the establishment and operational context of the ICRI-SAVe project, including its funding and duration, and explains its overarching purpose within Intel's broader autonomous driving initiatives.2.1. Establishment and FundingThe Intel Collaborative Research Institute on Safety of Autonomous Vehicles (ICRI-SAVe) was formally established by Intel Labs, Germany.1 The project commenced in September 2019 and was designed to run for a period of three years, concluding its activities in September 2022.1Financial backing for the project was provided by Intel Corporation, USA. The team at City, University of London, a key participant, received a specific grant of \$300,000 for their contributions to the initiative.1 This funding mechanism is characteristic of Intel Labs' broader investment strategy, which involves supporting university research programs globally. Intel typically provides grants ranging from $500,000 to $1.5 million per year to large universities and research institutes that are part of its worldwide network of Intel Collaborative Research Centers (ICRIs).42.2. Overarching Purpose and Strategic ImportanceThe fundamental purpose of the ICRI-SAVe project was to make significant advancements in the field of autonomous driving by enhancing both the functionality and, more importantly, the safety of automated driving vehicles.4 Intel Labs' European operations, including the ICRI at Intel Karlsruhe, are dedicated to ensuring the safety and security of Intelligent Autonomous Systems, a scope that encompasses not only automated driving vehicles but also other emerging technologies such as drones.4Intel views these academic collaborations as strategically vital for several interconnected reasons. Firstly, they serve to enhance Intel's visibility for talent acquisition and provide access to future developer communities, a concept referred to as "Intel mindshare".4 Secondly, these collaborations are designed to generate valuable research results and publications that can be directly integrated into new Intel products. This demonstrates a clear pathway from fundamental academic inquiry to tangible commercial application, highlighting Intel's commitment to translating research into market-ready solutions.4 Lastly, such partnerships facilitate early customer engagement and feedback, as evidenced by collaborative projects between universities and major automotive industry players like BMW or Siemens.4 The project was explicitly founded by Intel to "further research towards safe and trustworthy operation of Automated Vehicles," underscoring its central role in Intel's long-term vision for autonomous mobility.2Intel's engagement with ICRI-SAVe underscores a sophisticated research and development strategy that extends beyond purely internal innovation. By strategically funding fundamental research at leading academic institutions, Intel gains access to diverse, specialized expertise and fosters innovation in critical areas like safety assurance. This external research can then be integrated into their product lines, such as Mobileye's EyeQ chips and RSS framework, providing a scientific validation for their commercial offerings. This model allows Intel to mitigate risks associated with early-stage research and leverage external academic rigor, while simultaneously building a robust pipeline for future product development and market leadership in AV safety.The development of safe autonomous vehicles is not a siloed effort by a single company but rather a complex, multi-stakeholder ecosystem. Intel's ICRI model, including ICRI-SAVe, demonstrates a recognition that foundational safety research necessitates broad collaboration across academia, industry, and potentially government. This collaborative approach is essential for addressing the multifaceted challenges of AV safety, from technical assurance to regulatory frameworks, and for building a common understanding and acceptance of these transformative technologies. The technical focus of ICRI-SAVe was intended to contribute to this wider dialogue and standardization effort, fostering a more harmonized global approach to AV deployment.3. Core Research Objectives and MethodologiesThis section elaborates on the specific research objectives and the advanced methodologies employed by the ICRI-SAVe project, emphasizing its focus on formal and probabilistic approaches to autonomous vehicle safety.The ICRI-SAVe project was strategically structured around three primary research themes, each designed to address a critical aspect of autonomous vehicle safety.3.1. Assurance Cases and Formal ReasoningA key objective was the "structuring of assurance cases with increased semantics using Assurance 2.0".1 This involved building upon the established "claims, argument, evidence (CAE)" framework. The CAE framework is crucial for clearly articulating the chain of reasoning from empirical evidence to top-level safety claims, and for enabling the distinct separation and identification of inductive and deductive reasoning within safety arguments.1 This work aims to provide a more rigorous and transparent way to demonstrate that an autonomous system is acceptably safe.3.2. Statistical Inference and Probabilistic ModelingThe project extensively utilized statistical inference methods to support confidence in the safety of automated vehicles. This involved integrating experience from simulated or real-world operation with other available evidence through a Bayesian approach.1 Particular attention was paid to bounding methods, which enhance robustness to weakly supported assumptions, thereby ensuring the reliability of safety claims even when data might be incomplete or uncertain.1Probabilistic modeling of vehicle safety formed a core component, employing techniques such as stochastic activity networks (SAN) and Markov and semi-Markov models. These models were used to analyze the importance of various road hazards in different scenarios and to assess the impact of limited reliability of various subsystems, such as perception systems and safety monitors, on overall vehicle safety.13.3. Diversity and Machine Learning IntegrationResearch within this theme focused on analyzing the crucial role of diversity in enhancing the safety of AVs.1 This included developing justification and verification techniques specifically for machine learning (ML) components, which are increasingly integral to AV systems. A key aspect was the derivation of explanatory rules from ML models, directly addressing the "black box" problem often associated with AI decisions.1 The assessment of diversity in AV architecture and training processes was also a significant area of investigation, contributing to robust defence-in-depth strategies.1The overarching and explicit focus of the work across all themes was on "mathematical and probabilistic modelling," highlighting the project's commitment to rigorous, quantitative approaches to safety.1 These methodologies collectively aimed to address fundamental research questions from a comprehensive assurance case perspective, enabling the systematic structuring and critical challenging of claims and assumptions related to AV safety.1The project's objective to develop "justification and verification techniques for machine learning (including the derivation of explanatory rules)" directly confronts the challenge of understanding and trusting AI-driven decisions in autonomous systems. This issue, often termed the "black box" problem, is a major barrier to widespread AV adoption. Intel itself has highlighted the need for a "transparent safety model that builds trust between humans and machines".7 The inclusion of ML justification and verification techniques within ICRI-SAVe's core objectives demonstrates a proactive and forward-thinking approach to a significant challenge in AV deployment. By developing methods to derive "explanatory rules" from complex ML systems, the project aimed to make AV behavior more transparent, auditable, and ultimately, more trustworthy. This is crucial for gaining regulatory approval, establishing clear liability in case of incidents, and fostering public acceptance, moving beyond mere performance metrics to a deeper, more explainable understanding of safety guarantees. This directly supports the need for transparent safety models advocated by Intel.The strong emphasis on Bayesian approaches, probabilistic modeling (SAN, Markov/semi-Markov models), and formal assurance cases within ICRI-SAVe signifies a critical recognition that solely relying on billions of miles of real-world driving data for safety validation is both impractical and insufficient for highly complex AVs. The project aimed to develop more efficient and comprehensive methods to build confidence in safety before or in conjunction with extensive physical testing. This is achieved by mathematically combining diverse sources of evidence (e.g., simulated data, architectural analysis, development process data) to provide robust safety arguments. This approach is vital for accelerating AV development and deployment, as it offers a more scalable and rigorous way to demonstrate safety, reducing the prohibitive costs and time associated with purely empirical validation.The following table provides a clear, structured overview of the project's technical scope, making it easy for readers to grasp the core areas of research and the specific techniques employed. It reinforces the project's focus on rigorous, mathematical approaches to AV safety.Table 1: ICRI-SAVe Project Objectives and Key Methodologies
Research ThemeKey ObjectiveSpecific Methodologies/TechniquesAssurance Cases and Formal ReasoningStructuring of assurance cases with increased semantics using Assurance 2.0Claims, Argument, Evidence (CAE) framework; Separation and identification of inductive and deductive reasoning 1Statistical Inference and Probabilistic ModelingStatistical inference methods to support confidence in safety of automated vehiclesBayesian approach; Bounding methods for robustness to weakly supported assumptions 1Statistical Inference and Probabilistic ModelingProbabilistic modelling of safety of a vehicle to analyze importance of road hazards and impact of subsystem reliabilityStochastic Activity Networks (SAN); Markov and semi-Markov models 1Diversity and Machine Learning IntegrationAnalysis of diversity's role in safety of AVsJustification and verification techniques for machine learning (including derivation of explanatory rules); Assessment of diversity in architecture, training 1
4. Key Collaborators and Research TeamThis section identifies and describes the roles of the collaborating European universities and Intel Labs, highlighting the principal investigators and senior academics involved in the project.4.1. Academic and Industry PartnershipsThe ICRI-SAVe project was defined by its multi-institutional collaborative nature, bringing together Intel Labs, Germany, with several leading academic partners across Europe.1 The key collaborating institutions included:
Karlsruhe Institute of Technology (Germany) 1
FZI Research Center for Information Technology (Germany) 1
Fortis GmbH (Germany) 1
Technical University of Munich (Germany) 1
Fraunhofer IESE (Germany) 1
City, University of London (UK) 1
Intel Labs' approach to establishing these collaborations involves identifying leading universities renowned for specific areas of research. Projects are selected through a rigorous Request for Proposals (RFP) process, with the best proposals chosen by a technical committee comprising technical leaders from Intel Labs and Intel Business Groups.44.2. Principal Investigators and Research SupportThe core research work at City, University of London, a key participant, was led by three senior academics and significantly supported by PhD students whose studies were enabled by the ICRI funding, as well as academic colleagues and an MSc student.1 Researchers specifically involved in the work from City, University of London's Centre for Software Reliability (CSR) included:
Professor Peter Bishop 1
Dr. Andrey Povyakalo 1
Dr. Kizito Salako 1
Ms. Robab Aghazadeh Chakherlou 1
Mr. Mathew Stewart 1
Mr. Daniel Matvienko-Sikar 1
Dr. Francesco Terrosi 1
Professor Robin Bloomfield 2
Professor Lorenzo Strigini 1
Dr. Peter Popov 2
Professor Artur Garcez 2
City's team specifically focused their research on "Justifying the safety of autonomous vehicle systems," aligning with the project's broader objectives.2The list of collaborating institutions shows a strong concentration in Germany and the UK. This geographic clustering indicates that Intel Labs Germany strategically tapped into a specific regional cluster of excellence in software reliability, formal methods, and automotive engineering. It suggests that Germany and the UK are perceived as leading hubs for expertise in the highly specialized domain of safety-critical systems, which is directly relevant for autonomous driving. This concentration could also facilitate closer collaboration and more efficient knowledge transfer among the partners due to shared regulatory contexts within Europe and established academic networks.Beyond generating immediate research outcomes, the ICRI-SAVe project served as a crucial mechanism for talent development in the highly specialized and in-demand field of AV safety. By funding PhD and MSc students, Intel not only leveraged their research capabilities but also actively contributed to building a future workforce equipped with advanced skills in assurance cases, probabilistic modeling, and machine learning verification. This long-term investment in human capital is vital for sustaining innovation and addressing the complex, evolving safety challenges of autonomous systems, ensuring a pipeline of experts for both academia and industry.The table below provides a clear and concise visual representation of the collaborative nature of the project, highlighting the diverse academic expertise brought together by Intel. It reinforces the idea that AV safety is a complex, multi-disciplinary challenge requiring collective effort across institutions.Table 2: ICRI-SAVe Project Collaborators
Collaborating InstitutionCountrySpecific Contribution/Focus (if specified)Karlsruhe Institute of TechnologyGermanyGeneral collaborator 1FZI Research Center for Information TechnologyGermanyGeneral collaborator 1Fortis GmbHGermanyGeneral collaborator 1Technical University of MunichGermanyGeneral collaborator 1Fraunhofer IESEGermanyGeneral collaborator 1City, University of LondonUK"Justifying the safety of autonomous vehicle systems" 1
5. Research Outcomes and Publications This section summarizes the key findings and provides a comprehensive list of academic publications directly resulting from the ICRI-SAVe project, demonstrating its tangible contributions to the field.5.1. Summary of Key FindingsThe ICRI-SAVe project significantly advanced methodologies for structuring and analyzing safety assurance cases, particularly through the rigorous application of Assurance 2.0 and the Claims, Argument, Evidence (CAE) framework. This work provides a more semantic and verifiable approach to safety arguments, enhancing the ability to systematically demonstrate safety.1The project developed and applied sophisticated statistical inference methods, including Bayesian approaches and robust bounding methods, to quantify confidence in AV safety. These methods allowed for the effective combination of diverse evidence sources, such as data from simulated and real-world operations, architectural designs, and development processes.1Significant strides were made in probabilistic modeling of vehicle safety, utilizing techniques like stochastic activity networks (SAN) and Markov/semi-Markov models. This allowed for detailed studies on the impact of perception system imperfections and safety monitors on vehicle safety, especially in the presence of various road hazards.1Research also focused on the critical area of justification and verification techniques for machine learning components, including the derivation of explanatory rules, and the assessment of diversity in AV architecture and training. These contributions are vital for building trustworthy AI in safety-critical systems and enhancing defence-in-depth strategies.1The quality and impact of the team's work were recognized early, with a paper coauthored by Dr. Kizito Salako and Prof. Lorenzo Strigini, "Assessing the Safety and Reliability of Autonomous Vehicles from Road Testing," being selected for the best paper award at the 2019 International Symposium on Software Reliability Engineering (ISSRE).2The titles of the listed publications directly address practical aspects of AV safety development and deployment: "Bootstrapping confidence in future safety based on past safe operation," "Arguing safety of an improved autonomous vehicle from safe operation before the change," "Modelling road hazards and the effect on AV safety of hazardous failures," and "Assessing Safety-Critical Systems from Operational Testing." These themes indicate a clear focus on how to apply theoretical models and advanced methodologies to real-world scenarios and leverage existing operational data. The research outcomes of ICRI-SAVe were not purely theoretical exercises but aimed at providing actionable insights and methodologies directly applicable for AV developers and regulatory bodies. By focusing on topics like "bootstrapping confidence" from past operations or "arguing safety of an improved AV," the project directly addressed the practical challenges of continuous validation, incremental development, and operational safety assessment in the AV lifecycle. This practical orientation significantly increases the likelihood of the research being adopted and influencing industry practices, contributing to tangible improvements in AV safety.5.2. Comprehensive Publication ListThe following publications directly resulted from the ICRI-SAVe project, primarily from the contributions of City, University of London, and its collaborators:
Bishop, P., Povyakalo, A. & Strigini, L. (2022). "Bootstrapping confidence in future safety based on past safe operation." 2022 IEEE 33rd International Symposium on Software Reliability Engineering (ISSRE 2022), 31 Oct - 3 Nov 2022, Charlotte, NC, USA.1
Aghazadeh Chakherlou, R., Salako, K. & Strigini, L. (2022). "Arguing safety of an improved autonomous vehicle from safe operation before the change: new results." RAIS 2022 2nd International Workshop on Reliability of Autonomous Intelligent Systems, 31 Oct - 3 Nov 2022, Charlotte, NC, USA.1
Buerkle, C., Oboril, F., Popov, P. T., and Strigini, L. (2022). "Modelling road hazards and the effect on AV safety of hazardous failures." The 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022), 8 Oct - 12 Oct 2022, Macau, China.1
Terrosi, F., Strigini, L., Bondavalli, A. (2022). "Impact of Machine Learning on Safety Monitors.".1
Bishop, P., Povyakalo, A., Strigini, L., & Zhao, X. (2021). "Conservative Confidence Bounds in Safety, from Generalised Claims of Improvement & Statistical Evidence." 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), 2021, pp. 451-462.1
Zhao, X., Salako, K., Strigini, L. (2020). "Assessing Safety-Critical Systems from Operational Testing: A Study on Autonomous Vehicles." Information and Software Technology, 128, 106393.1
Bloomfield, R. and Rushby, J. (2021). "Assurance 2.0: A manifesto." In Mike Parsons and Mark Nicholson, editors, Systems and Covid-19: Proceedings of the 29th Safety-Critical Systems Symposium (SSS'21), pages 85–108, Safety-Critical Systems Club, York, UK.1
Rushby, J..1 Note: Full publication details for this specific entry are not provided in the source material, indicating it may be an ongoing or related work.
The project's robust publication record demonstrates a significant contribution to the academic and scientific understanding of autonomous vehicle safety. Their acceptance and recognition in top-tier, peer-reviewed venues signify the rigor, novelty, and intellectual merit of the research conducted. This foundational knowledge is critical for the long-term advancement of the field, providing a strong scientific basis for future AV design, validation, and regulatory frameworks. The "test of time" award for related work from City's CSR highlights that ICRI-SAVe built upon and extended a strong legacy of software reliability and dependable systems research, ensuring the project's outputs are grounded in established scientific principles.2The following table provides a quick, organized reference for the project's tangible academic outputs. It showcases the academic rigor and the specific research areas that resulted in peer-reviewed publications.Table 3: Select Publications from the ICRI-SAVe Project
Publication TitleAuthorsVenue/JournalYearKey Research Area Addressed"Bootstrapping confidence in future safety based on past safe operation"Bishop, P., Povyakalo, A. & Strigini, L.2022 IEEE 33rd International Symposium on Software Reliability Engineering (ISSRE 2022)2022Statistical inference, confidence in AV safety from operational data 1"Arguing safety of an improved autonomous vehicle from safe operation before the change: new results"Aghazadeh Chakherlou, R., Salako, K. & Strigini, L.RAIS 2022 2nd International Workshop on Reliability of Autonomous Intelligent Systems2022Assurance cases, statistical inference for AV safety improvements 1"Modelling road hazards and the effect on AV safety of hazardous failures"Buerkle, C., Oboril, F., Popov, P. T., and Strigini, L.The 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022)2022Probabilistic modeling of road hazards and subsystem reliability 1"Impact of Machine Learning on Safety Monitors"Terrosi, F., Strigini, L., Bondavalli, A.N/A (conference/journal not specified)2022Machine learning verification, safety monitors 1"Conservative Confidence Bounds in Safety, from Generalised Claims of Improvement & Statistical Evidence"Bishop, P., Povyakalo, A., Strigini, L., & Zhao, X.2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)2021Statistical inference, Bayesian reasoning, bounding methods 1"Assessing Safety-Critical Systems from Operational Testing: A Study on Autonomous Vehicles"Zhao, X., Salako, K., Strigini, L.Information and Software Technology2020Operational testing, safety assessment of AVs 1"Assurance 2.0: A manifesto"Bloomfield, R. and Rushby, J.Systems and Covid-19: Proceedings of the 29th Safety-Critical Systems Symposium (SSS'21)2021Assurance cases, formal reasoning 1
6. Impact and Legacy on Autonomous Vehicle SafetyThis section analyzes the broader impact and legacy of the ICRI-SAVe project, focusing on its contributions to safety frameworks, influence on industry practices, and role in addressing public trust and regulatory challenges.6.1. Contribution to Safety Frameworks and StandardsICRI-SAVe's foundational research in assurance cases, probabilistic modeling, and machine learning verification provides a robust scientific basis for the development of transparent and verifiable AV safety frameworks.1 While the specific project objectives of ICRI-SAVe do not explicitly list Responsibility-Sensitive Safety (RSS) 6, Intel's broader strategy indicates that Collaborative Research Institutes, including those in Europe, explore AV safety using RSS as a foundational concept for their research.5 This highlights a strategic alignment where ICRI-SAVe's expertise in mathematical and probabilistic modeling could directly inform or validate aspects of RSS.RSS, developed by Mobileye (an Intel company), is a formal, mathematical model that translates human notions of safe driving into verifiable rules, aiming for transparency and clarity in AV decision-making. It defines a "Safe State" where the autonomous vehicle cannot be the cause of an accident.6 The emphasis on formal mathematical models in RSS allows for safety testing that can be verified without requiring millions of miles of physical driving, thereby significantly reducing the validation burden. This aligns directly with ICRI-SAVe's focus on statistical inference and probabilistic modeling to support confidence in AV safety.1 Intel's advocacy for a "universally acceptable and understood safety standard" like RSS 7 suggests that the rigorous methodologies explored by ICRI-SAVe contribute to the intellectual groundwork necessary for such industry-wide and globally harmonized standards.The interplay between ICRI-SAVe's deep academic research on mathematical and probabilistic modeling for AV safety and Intel's (through Mobileye) strong advocacy for RSS as a "universally acceptable and understood safety standard" 7 indicates a symbiotic relationship. This dynamic suggests that foundational academic research informs and strengthens proposed industry standards, while industry needs, in turn, guide academic inquiry. This strategic synergy is vital for the maturation of the AV industry. Academic research provides the theoretical rigor and mathematical underpinnings necessary to validate and evolve industry-proposed standards, ensuring they are scientifically sound and robust. In turn, these standards provide a practical framework and real-world problems for academic research to address, ensuring relevance. This collaborative dynamic accelerates the development of both highly robust safety technologies and widely accepted regulatory frameworks, which are crucial for the mass deployment of AVs globally.6.2. Influence on Industry PracticesThe project's deep focus on mathematical and probabilistic modeling, particularly for analyzing the importance of road hazards and the reliability of various AV subsystems 1, directly informs and improves the design, testing, and validation processes of AV perception systems and safety monitors within the industry. The research into "justification and verification techniques for machine learning" 1 is critical for the safe and reliable integration of AI components into safety-critical AV systems, providing methodologies to ensure their dependable operation and explainability, which is a growing industry concern.13By demonstrating the feasibility and benefits of formal verification and robust confidence measures, ICRI-SAVe's work encourages a vital shift in industry practices from an over-reliance on purely empirical validation (e.g., miles driven) to a more sophisticated hybrid approach that combines extensive testing with formal arguments and probabilistic guarantees.6 The project's contributions align with the broader industry and regulatory imperative to establish a "rigorous process that ensures safety for all road users without demanding too much from AV providers," fostering efficient yet safe development.14The work of ICRI-SAVe, in conjunction with Intel's advocacy for RSS, points to a fundamental and necessary shift in how autonomous vehicle safety is proven. Instead of relying primarily on a prohibitive amount of real-world driving data—which is difficult to collect, expensive, and may not adequately cover all "edge cases"—the focus is moving towards a more formal, model-based, and probabilistic approach. This allows for a more efficient and comprehensive demonstration of safety by combining diverse data sources (simulations, architectural analysis, development process data) with mathematical proofs. This paradigm shift is essential for the economic viability and scalability of AV technology, as it significantly reduces the immense cost, time, and logistical challenges associated with purely empirical validation.6.3. Addressing Public Trust and Regulatory ChallengesA significant barrier to the widespread adoption of autonomous vehicles is public fear and uncertainty regarding their safety.7 ICRI-SAVe's emphasis on transparent, verifiable safety arguments through assurance cases and formal modeling 1 directly addresses this by providing a basis for explainable safety. Intel explicitly articulates the need to "bridge the gap between acceptance of today's automated driving assist features and full autonomy" by creating a "transparent safety model that builds trust between humans and machines".7 ICRI-SAVe's work contributes directly to this transparency and trust-building effort.The project's research provides essential tools and methodologies that can help regulators and policymakers develop a more intimate understanding of AV safety, thereby enabling them to shape effective and appropriate policies for future mobility.14 The concept of "Responsibility-Sensitive Safety" (RSS), which is explored by Intel's broader ICRI network, aims to formalize fault assignment in AV accidents.8 This is a critical legal and public trust issue that robust safety frameworks must address. The project's outputs, by providing methods to assess confidence and model risks, support the "Safe System Approach" advocated by entities like NHTSA, which aims to reduce traffic deaths and injuries through advanced vehicle safety technologies.15The ICRI-SAVe project was hosted at City, University of London's Centre for Software Reliability (CSR).1 CSR has a documented history of impactful research in dependable systems, including a "test of time" award for work on "OS diversity for intrusion tolerance".2 ICRI-SAVe's themes include "diversity and defence-in-depth" and "systemic risk modelling" with a focus on "mathematical and probabilistic modelling".1 The strategic choice of City's Centre for Software Reliability as a key partner underscores the critical importance of software reliability engineering and dependable systems principles in achieving AV safety. Autonomous vehicles are inherently complex software-intensive systems, and their safety relies heavily on the correctness, robustness, and fault tolerance of their underlying software. ICRI-SAVe's work on assurance cases, diversity, and probabilistic modeling directly applies established software reliability concepts and expertise, leveraging decades of research in safety-critical software, to the unique and evolving challenges of autonomous driving. This highlights that AV safety is fundamentally a software engineering challenge, requiring deep expertise beyond just hardware or AI algorithms.7. Conclusion and Future Outlook7.1. Summary of AchievementsThe ICRI-SAVe project successfully completed its three-year mandate, delivering foundational and impactful research in critical areas of autonomous vehicle safety.1 Its primary achievements lie in advancing methodologies for rigorous safety assurance cases (through Assurance 2.0 and the CAE framework), developing sophisticated statistical inference and probabilistic modeling techniques for quantifying confidence and analyzing risk, and exploring the vital role of diversity and machine learning verification in complex AV systems.1 The project fostered significant academic collaboration across leading European institutions, effectively leveraging specialized expertise to tackle complex, multi-faceted safety challenges.1 Through its peer-reviewed publications, ICRI-SAVe contributed valuable scientific knowledge to the global discourse on dependable autonomous systems, earning recognition in top-tier academic venues and demonstrating the rigor of its research.17.2. Lasting Contributions and Future OutlookThe project's emphasis on formal, mathematical, and probabilistic approaches to safety assurance provides a robust alternative and crucial complement to traditional, mileage-based validation methods. This approach is paramount for the scalability, economic viability, and broad deployment of AV technology.1 Its work directly informs the development of transparent and verifiable safety frameworks, such as Intel's Responsibility-Sensitive Safety (RSS) model, which are essential for building public trust, facilitating regulatory alignment globally, and addressing liability concerns.6 The methodologies developed, particularly concerning machine learning justification and the role of diversity, will continue to be vital as autonomous vehicle systems become increasingly complex, interconnected, and reliant on advanced artificial intelligence.1The fundamental problem addressed by ICRI-SAVe—how to prove safety for highly complex, AI-driven systems operating in unpredictable real-world environments—remains a central challenge. The "long tail" problem, where AVs encounter rare but critical events they have not seen before, persists despite vast data collection efforts.16 The project's legacy is in laying the groundwork for methodologies that can provide robust safety assurances even for unforeseen and rare scenarios, by enabling reasoning about system behavior and uncertainty rather than relying solely on observed data. This suggests that the influence of ICRI-SAVe's research extends far beyond its operational duration, shaping the fundamental philosophical and methodological approaches to AV safety certification and validation for years to come.The need for continued research in these foundational areas remains paramount. As autonomous vehicle technology evolves, ongoing efforts are required to ensure safety, address emerging challenges (such as the cyber-resilience of Connected and Autonomous Vehicles, as highlighted by ongoing research stemming from ICRI-SAVe 9), and adapt to dynamic regulatory landscapes.9The ultimate impact and legacy of foundational research projects like ICRI-SAVe depend heavily on the successful translation of their technical advancements into widely accepted industry standards and effective regulatory frameworks. While the project provided sophisticated scientific tools for rigorous safety assessment, the broader challenge remains in achieving consensus among diverse stakeholders (industry, regulators, public) on what constitutes "safe enough" for autonomous vehicles to operate at scale. Intel's own studies indicate that consumers harbor fears about AVs 7, and regulators need to understand how deployments will affect citizens' lives.14 The World Economic Forum emphasizes the critical need for a "multistakeholder approach" and "harmonizing approaches" to AV safety assessment for successful deployment.14 The legacy of ICRI-SAVe will be measured by how its contributions facilitate this crucial transition from academic innovation to practical, global deployment through transparent, verifiable, and trusted safety paradigms, ultimately accelerating the realization of safer and more trustworthy autonomous mobility. The mention of "cyber-resilience of Connected and Autonomous Vehicles (CAVs)" as a future focus 9 further indicates the evolving and expanding nature of the safety challenge, requiring continuous research and collaboration.

% last but not least, a paper by kizito and lorenzo, cite simulation - https://arxiv.org/pdf/1908.06540
\section{Objectives}
