%%%%%%%%%%%%%
%% CONTEXT %%
%%%%%%%%%%%%%

%This chapter explains the current state of your topic, in practice and theory. This is the state of the world which you intend to improve, and the state of knowledge on top of which you build your advances and from which you learn knowledge to apply and constraints on your work. So, you will report and analyse what is known about a certain topic, as reported in reference literature and published scientific literature; if you are developing a product, you will need to report about comparable or competing products over which you intend to improve or from which you will obtain ideas; you may need to describe legal or societal situation within which your work takes place; etc.  
  
%It is important to demonstrate scholarship, i.e. the ability to read about a subject area in a range of sources, assimilate the material and then discuss it intelligently.  
  
%You should demonstrate that you understand what you have read by providing some analysis or commentary in view of the goals of your project: it is not enough simply to provide summaries of what you have read. References should be cited following the Harvard Referencing Style. You must also explain, both in this chapter and, as appropriate, in others, how the results of the studies to which you make reference inform your project work. To gain a passing grade, your report MUST demonstrate adequate engagement with academic literature and any other sources necessary for the work to be well informed.  

% The story we want to tell
% (...)

\chapter{Context}
\label{Context} 

There have been calls for a more systematic and comprehensive approach to software testing in order to ensure the quality and safety of autonomous vehicles, embodied in efforts such as adapting the ISO 26262 development V process to address the unique testing problems encountered in autonomous vehicles. Major challenge areas in testing, such as the driver being out of the loop and dealing with non-deterministic algorithms, can be addressed by general solution approaches including phased deployment, architecture separation, and fault injection for more efficient testing (\cite{koopman2016challenges}).

Society is increasingly reliant on autonomous systems,  being used in a wide variety of industries, including IT, finance, transportation, medical surgery, and industrial automation. Autonomous systems are automating tasks that were once done by humans, and they are doing so with increasing accuracy and efficiency (\cite{ebert2019validation}).


%%%%%%%%%%%%%%%%%
% DISTRUST IN AI

As of mid-2023, there remains a significant level of distrust in artificial intelligence (AI) among the general public and certain sectors (\cite{futureoflife2023pausegiantai}). This distrust stems from several sources. Firstly, there's the opacity of AI decision-making processes, often referred to as the "black box" (\cite{burrell2016}) problem, which makes it difficult to understand how AI systems arrive at specific outcomes. This lack of transparency can lead to skepticism and uncertainty. Secondly, there are concerns about the potential misuse of AI in areas like surveillance, data privacy, and military applications. Additionally, people worry about the societal implications of AI, such as job displacement due to automation and the deepening of socio-economic inequalities. Lastly, instances of AI systems demonstrating bias — because they've been trained on biased data or because of issues in their design — have also led to a lack of trust. These issues underline the importance of the ongoing discussions and initiatives centered on AI ethics, transparency, and regulation.

The potential of automated and autonomous systems to improve quality of life is vast. For example, autonomous mobility systems have the potential to eliminate up to 90\% of accidents and reduce commuting time by up to 50\% (\cite{kalra2016driving}).

The Society of Automotive Engineers (SAE) \cite{sae_org} International  is a global association of over 128,000 engineers and technical experts in the aerospace, automotive, and commercial vehicle industries. Founded in 1905, its mission is to advance mobility knowledge and solutions, through initiatives such a education and the development of standards, such as the J3016, Establishing uniform levels of driving automation and related terminology that fulfills multiple objectives, such as

levels of driving automation which defines six levels of driving automation, from Level 0 to Level 5:

\begin{enumerate}
    \item Level 0 - No Automation: The human driver does all the driving.
    \item Level 1 - Driver Assistance: The vehicle can assist with some functions, but the human driver does most of the driving.
    \item Level 2 - Partial Automation: The vehicle has combined automated functions like acceleration and steering, but the human driver must remain engaged with the driving task and monitor the environment at all times.
    \item Level 3 - Conditional Automation: The vehicle can manage most aspects of driving, including monitoring the environment. The driver must be ready to take control at any time.
    \item Level 4 - High Automation: The vehicle can perform all driving tasks under certain conditions. The driver may have the option to control the vehicle.
    \item Level 5 - Full Automation: The vehicle can perform all driving tasks, under all conditions that a human driver could perform them. No human attention is required.
\end{enumerate}

The core features expected from an autonomous vehicle simulation environment to validate self driving AIs:

\begin{enumerate}
\item Realistic Environments: The simulation environment should mimic real-world conditions as closely as possible. This includes realistic landscapes, road conditions, buildings, and all other aspects of the physical world that a self-driving vehicle might encounter. It should also simulate various weather conditions like rain, snow, fog, and different times of day.
\item Dynamic Objects: Besides static objects, the simulator should be able to incorporate dynamic objects such as other vehicles, pedestrians, cyclists, and animals that move and behave as they would in real life.
\item Sensor Simulation: The environment should be able to simulate the data from the different sensors used in autonomous vehicles. This includes lidar, radar, ultrasonic sensors, and cameras. The data should closely match the real-world data that these sensors would capture.
\item Physics-based Modeling: The simulator should incorporate realistic physics to correctly model vehicle dynamics, tire-road interaction, and other physical phenomena.
\item Scalability: The simulation environment should be scalable to test multiple scenarios and vehicle models. It should also be able to handle large-scale simulations to test fleet operations.
\item Flexibility: The environment should allow for a wide range of scenarios to be simulated, including rare or dangerous situations that may not be feasible or safe to test in real-world conditions.
\item Repeatability: It should be possible to reproduce exact conditions and scenarios multiple times. This is crucial for validating results and debugging issues.
\item Integration with AI Development Platforms: The simulator should be able to integrate with AI development platforms, allowing for the training and testing of AI models within the simulation environment.
\item Performance Metrics: The simulator should provide a way to measure and evaluate the performance of the self-driving AI. This could include metrics like decision-making time, adherence to traffic rules, safety metrics, etc.
\item Multi-Agent Environment: The simulator should support multi-agent environments, where multiple self-driving vehicles can interact with each other and the environment.
\item Hardware-in-the-loop Simulation: For more advanced testing, the simulator should support hardware-in-the-loop (HIL) simulation. This allows for real vehicle components to be tested in conjunction with the simulation.
\end{enumerate}

\section{Surveys}

% https://scholar.google.co.uk/scholar?q=A+survey+on+simulation+environments+for+autonomous+driving+research&hl=en&as_sdt=0&as_vis=1&oi=scholart

\cite{kaur2021survey} provide a comprehensive review of simulators for testing self-driving cars. They begin by discussing the motivation and background, including the increasing complexity of automotive software and the need for rigorous testing. The authors then identify key requirements for an ideal autonomous vehicle simulator, covering perception, localization/mapping, path planning, vehicle control, virtual environments, traffic infrastructure, scenario simulation, ground truth data, and software qualities. Six commonly used open-source simulators (MATLAB, CarSim, PreScan, Gazebo, CARLA, LGSVL) are reviewed in detail. Through comparison, the authors find CARLA and LGSVL to be most suitable for end-to-end testing of self-driving capabilities, while other simulators have strengths in specific sub-areas. Key challenges for simulation are also discussed, such as lack of standards and inability to test connected vehicles. Overall, this survey offers a comprehensive overview of simulators for developing and testing self-driving car systems.


Anomaly detection is an important capability for autonomous vehicles to safely handle rare events and corner cases encountered on the road. Researchers have surveyed techniques for detecting anomalies across different sensor modalities commonly used in autonomous driving systems, including cameras, lidars, radars, and multimodal data fusion. Key challenges involve identifying unknown obstacles, weather effects, collective anomalies that differ from normal patterns, and eliminating false ghosts targets. Promising approaches utilize confidence scores, reconstruction, prediction, generative models, and temporal feature analysis. The survey categorizes techniques based on anomaly level, sensor modality, datasets used, and online deployment capability. It provides a landscape of anomaly detection methods and datasets, while highlighting open research questions around factors like lack of lidar and radar benchmarks. Overall, the paper delivers a valuable reference for researchers advancing anomaly detection for robust perception in autonomous driving (\cite{bogdoll2022anomaly})



\cite{Yurtsever_2020} provide a comprehensive overview of the state-of-the-art in automated driving systems (ADS). They discuss the potential benefits of ADS, including preventing accidents and reducing emissions, as well as challenges such as handling complex urban environments. The authors review system architectures, including modular versus end-to-end approaches, sensors and hardware, and core ADS functions like localization, mapping, perception, planning, control, human-machine interaction, and risk assessment. Key perception tasks covered include 2D and 3D object detection, semantic segmentation, lane/road detection, and object tracking. Planning methods reviewed include global and local (motion) planning. The paper concludes with a summary of publicly available datasets and software tools for ADS development and testing. Overall, this paper offers a thorough review of the current practices, emerging technologies and open challenges in developing robust automated driving systems.

\subsection{Path planning}

@inproceedings{kuwata2009real,
  title={Real-time motion planning with applications to autonomous urban driving},
  author={Kuwata, Yoshiaki and Fiore, Gaston A and Teo, Justin and Frazzoli, Emilio and How, Jonathan P},
  booktitle={2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4749--4755},
  year={2009},
  organization={IEEE}
}

\subsection{Self-driving platforms}

The desirable features of self-driving platforms arguably are:

* Localization stack
* Surround view
* GPS
* Object detection, classification and segmentation
* Intended path of moving objects
* 

\section{Features of Autoware}

Autoware is an open-source software project that provides a complete set of self-driving modules, including localization, detection, prediction, planning, and control. It is designed to be modular and scalable, so that it can be used in a variety of vehicles and applications.

Here are some of the key features of Autoware:

\begin{itemize}
  \item **Modular architecture:** Autoware is designed as a modular system, with each module responsible for a specific task. This makes it easy to add or remove modules, and to customize Autoware for different applications.
  \item **Open source:** Autoware is open source software, which means that it is freely available to anyone to use, modify, and distribute. This makes it a valuable resource for the autonomous driving community, and it allows for rapid development and innovation.
  \item **Comprehensive documentation:** Autoware comes with comprehensive documentation, which includes tutorials, reference guides, and API documentation. This makes it easy to learn how to use Autoware, and to get started developing autonomous driving applications.
  \item **Active community:** Autoware has a large and active community of developers and users. This community provides support and resources for users of Autoware, and it helps to drive the development of the project.
\end{itemize}

Some of the specific features of Autoware include:

\begin{itemize}
  \item **Localization:** Autoware provides a variety of localization algorithms, including GPS, IMU, and LIDAR.
  \item **Detection:** Autoware can detect a variety of objects in the environment, including vehicles, pedestrians, cyclists, and traffic signs.
  \item **Prediction:** Autoware can predict the behavior of other road users, which helps it to plan safe and efficient trajectories.
  \item **Planning:** Autoware can plan safe and efficient trajectories for the vehicle to follow.
  \item **Control:** Autoware can control the vehicle's steering, acceleration, and braking.
\end{itemize}

Autoware is a powerful and versatile software platform for autonomous driving. It is used by a variety of companies and research institutions around the world, and it is actively being developed and improved.


From ChatGPT:

Autoware is an open-source software for self-driving vehicles. As of my knowledge cutoff in September 2021, some of the core features of Autoware include:

1. **3D Localization**: It can accurately identify the vehicle's position in a pre-mapped area using sensor inputs.

2. **3D Mapping**: Autoware supports creating detailed 3D maps of environments, which are crucial for the autonomous navigation.

3. **Obstacle Detection**: It can recognize obstacles in the environment in real-time using sensor data. This is important for safe navigation.

4. **Object Tracking**: Autoware can track moving objects such as pedestrians and other vehicles, which is critical for decision-making and action-taking in a dynamic environment.

5. **Path Planning**: The software can plan the optimal path from point A to point B, considering the environment and other factors.

6. **Vehicle Control**: It can execute the planned path by controlling the vehicle's steering, acceleration, and braking.

7. **Simulations**: Autoware also supports simulations, allowing developers to test and fine-tune their autonomous driving algorithms in a safe and controlled environment before deploying them in the real world.

8. **Sensor Fusion**: Autoware can integrate data from different types of sensors such as Lidar, radar, cameras, and GPS, among others, to create a more holistic understanding of the environment.

9. **Software Architecture**: Autoware uses a flexible and modular software architecture based on ROS (Robot Operating System), which allows easy integration and customization with various hardware platforms and software components.

10. **Data Logging and Visualization**: It supports logging and visualizing data for analysis and debugging.

Remember that this information is based on the state of Autoware as of 2021, and additional features or changes may have occurred after that time. Please check the latest documentation for the most up-to-date information.


From Claude:

Here are some key features of Autoware, an open-source software for self-driving vehicles:

- Sensor integration - Autoware is designed to work with many different sensors like cameras, LiDAR, RADAR, etc. It provides drivers and interfaces to integrate these different sensors.

- Perception - The perception module includes detection and tracking of objects like vehicles, pedestrians, lanes, traffic signs etc. using sensor data. Algorithms like deep learning are used for object recognition.

- Localization - Autoware offers localization algorithms like particle filter based localization to estimate the precise location of the ego vehicle using map data and sensor inputs.

- Mapping - Maps can be created by merging LiDAR point cloud data. Autoware also supports usage of pre-built maps.

- Motion Planning - This module plans the trajectory and speed of the vehicle to enable autonomous driving. Algorithms used include lattice planner, waypoint follower etc. 

- Control - The vehicle control module outputs appropriate throttle, brake and steering commands to execute the planned trajectory. 

- Route Planning - Route planning algorithms can plan global routes from source to destination in the road network.

- Vehicle Integration - Autoware is designed to be hardware independent and can be integrated with many vehicle platforms via ROS.

- Safety - Safety features include emergency stop, collision avoidance, fail-safes, redundancy etc.

- Open Source - Autoware is open-source and allows community contributions to the self-driving software stack.

In summary, Autoware provides a full stack solution for autonomous driving which is modular, hardware independent and supports collaboration through its open source model.


\subsection{Autoware}

\section{Integration of Autoware and CARLA}

Autoware is an open-source software project that provides a complete set of self-driving modules, including localization, detection, prediction, planning, and control. It is designed to be modular and scalable, so that it can be used in a variety of vehicles and applications.

CARLA is a simulator for autonomous driving research. It provides a realistic environment in which to test and evaluate autonomous driving algorithms. CARLA is based on the Unreal Engine, which is a powerful game engine that can be used to create realistic and immersive environments.

The integration of Autoware and CARLA allows users to test and evaluate Autoware's algorithms in a realistic environment. This is important because it allows users to see how Autoware performs in different scenarios, such as traffic jams and intersections. The integration is achieved through the use of ROS, a middleware for robotics. ROS provides a common platform for Autoware and CARLA to communicate with each other.

The integration of Autoware and CARLA has a number of benefits. First, it allows users to test Autoware's algorithms in a realistic environment. This is important because it allows users to see how Autoware performs in different scenarios. Second, the integration allows users to debug Autoware's algorithms more easily. This is because CARLA provides a variety of tools for debugging, such as a playback function that allows users to replay past simulations.

The integration of Autoware and CARLA is a valuable tool for autonomous driving research. It allows users to test and evaluate Autoware's algorithms in a realistic environment, and it makes it easier to debug Autoware's algorithms.

\begin{itemize}
  \item Autoware is an open-source software project that provides a complete set of self-driving modules.
  \item CARLA is a simulator for autonomous driving research that provides a realistic environment in which to test and evaluate autonomous driving algorithms.
  \item The integration of Autoware and CARLA allows users to test and evaluate Autoware's algorithms in a realistic environment.
  \item The integration of Autoware and CARLA has a number of benefits, including the ability to test Autoware's algorithms in different scenarios and to debug Autoware's algorithms more easily.
\end{itemize}

\section{Features of Autoware}

Autoware is an open-source software project that provides a complete set of self-driving modules, including localization, detection, prediction, planning, and control. It is designed to be modular and scalable, so that it can be used in a variety of vehicles and applications.

Here are some of the key features of Autoware:

\begin{itemize}
  \item **Modular architecture:** Autoware is designed as a modular system, with each module responsible for a specific task. This makes it easy to add or remove modules, and to customize Autoware for different applications.
  \item **Open source:** Autoware is open source software, which means that it is freely available to anyone to use, modify, and distribute. This makes it a valuable resource for the autonomous driving community, and it allows for rapid development and innovation.
  \item **Comprehensive documentation:** Autoware comes with comprehensive documentation, which includes tutorials, reference guides, and API documentation. This makes it easy to learn how to use Autoware, and to get started developing autonomous driving applications.
  \item **Active community:** Autoware has a large and active community of developers and users. This community provides support and resources for users of Autoware, and it helps to drive the development of the project.
\end{itemize}

Some of the specific features of Autoware include:

\begin{itemize}
  \item **Localization:** Autoware provides a variety of localization algorithms, including GPS, IMU, and LIDAR.
  \item **Detection:** Autoware can detect a variety of objects in the environment, including vehicles, pedestrians, cyclists, and traffic signs.
  \item **Prediction:** Autoware can predict the behavior of other road users, which helps it to plan safe and efficient trajectories.
  \item **Planning:** Autoware can plan safe and efficient trajectories for the vehicle to follow.
  \item **Control:** Autoware can control the vehicle's steering, acceleration, and braking.
\end{itemize}

Autoware is a powerful and versatile software platform for autonomous driving. It is used by a variety of companies and research institutions around the world, and it is actively being developed and improved.

%%%%%%%%%%%%%%%%%%%%
% RELATED WORK
%%%%%%%%%%%%%%%%%%%%

% \section{Related Work}
% \label{context:related-work}








