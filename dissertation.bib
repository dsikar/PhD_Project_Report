%% Referencing
%% See https://www.bibtex.com/e/entry-types/
%% for Complete list of BibTeX entry types [with examples] - BibTeX.com
%% To validate: https://biblatex-linter.herokuapp.com/validate

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% INTRODUCTION AND OBJECTIVES %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CONTEXT / LITERATURE REVIEW %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% SAFECOMP 2014
% TODO synopsys discusson
@book{bondavalli2014computer,
  title={Computer Safety, Reliability, and Security: SAFECOMP 2014 Workshops: ASCoMS, DECSoS, DEVVARTS, ISSE, ReSA4CI, SASSUR. Florence, Italy, September 8-9, 2014, Proceedings},
  author={Bondavalli, Andrea and Ceccarelli, Andrea and Ortmeier, Frank},
  volume={8696},
  year={2014},
  publisher={Springer}
}

%
%
%
% TODO synopsys discusson
% Reference to RTCA ASPS
@inproceedings{bieber2014safety,
  title={From safety models to security models: preliminary lessons learnt},
  author={Bieber, Pierre and Brunel, Julien},
  booktitle={International Conference on Computer Safety, Reliability, and Security},
  pages={269--281},
  year={2014},
  organization={Springer}
}

%
%
%
% TODO synopsys discusson
% RTCA ASPS
@book{rtca2014airworthiness,
  title={Airworthiness Security Process Specification},
  author={RTCA (Firm). SC-216},
  year={2014},
  publisher={RTCA, Incorporated}
}

%
%
%
% TODO synopsys discusson
@misc{bloomfield2021safety,
      title={Safety Case Templates for Autonomous Systems}, 
      author={Robin Bloomfield and Gareth Fletcher and Heidy Khlaaf and Luke Hinde and Philippa Ryan},
      year={2021},
      eprint={2102.02625},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

% https://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/nyas.14593
% From convolutional neural networks to models of higher-level cognition (and back again)

% From convolutional neural networks to models of higher-level cognition (and back again) 

%
%
%
%
@inproceedings{de2011neural,
  title={A neural-symbolic cognitive agent for online learning and reasoning},
  author={de Penning, H Leo H and Garcez, Artur S d'Avila and Lamb, Lu{\'\i}s C and Meyer, John-Jules C},
  booktitle={Twenty-Second International Joint Conference on Artificial Intelligence},
  year={2011}
}


%
%
%
%
@inproceedings{townsend2020eric,
  title={ERIC: Extracting Relations Inferred from Convolutions},
  author={Townsend, Joe and Kasioumis, Theodoros and Inakoshi, Hiroya},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2020}
}

%
% Fairness in AI
@inproceedings{city26151,
       booktitle = {AAAI 2021 Spring Symposium on Combining Machine Learning and Knowledge Engineering (AAAI-MAKE 2021)},
          volume = {2846},
           title = {Neural-symbolic integration for fairness in AI},
          author = {B. Wagner and A. S. d'Avila Garcez},
            year = {2021},
            note = {{\copyright} 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
         journal = {CEUR Workshop Proceedings},
        keywords = {Neurosymbolic AI, Deep Learning with Knowledge Representation, Fairness, Explainability},
             url = {https://openaccess.city.ac.uk/id/eprint/26151/},
        abstract = {Deep learning has achieved state-of-the-art results in various application domains ranging from image recognition to language translation and game playing. However, it is now generally accepted that deep learning alone has not been able to satisfy the requirement of fairness and, ultimately, trust in Artificial Intelligence (AI). In this paper, we propose an interactive neural-symbolic approach for fairness in AI based on the Logic Tensor Network (LTN) framework. We show that the extraction of symbolic knowledge from LTN-based deep networks combined with fairness constraints offer a general method for instilling fairness into deep networks via continual learning. Explainable AI approaches which otherwise could identify but not fix fairness issues are shown to be enriched with an ability to improve fairness results. Experimental results on three real-world data sets used to predict income, credit risk and recidivism in financial applications show that our approach can satisfy fairness metrics while maintaining state-of-the-art classification performance.}
}

%
%
%
@INPROCEEDINGS{9206844,
  author={Charitou, Charitos and Garcez, Artur d’Avila and Dragicevic, Simo},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Semi-supervised GANs for Fraud Detection<sup>*</sup>}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/IJCNN48605.2020.9206844}
}

%
% Explainability
%
@misc{white2019measurable,
      title={Measurable Counterfactual Local Explanations for Any Classifier}, 
      author={Adam White and Artur d'Avila Garcez},
      year={2019},
      eprint={1908.03020},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

%
%
%
@incollection{city25605,
          number = {1248},
           month = {July},
          author = {K. H. Ngan and A. d'Avila Garcez and K. Knapp and A. Appelboam and C. C. Reyes-Aldasoro},
          series = {Communications in Computer and Information Science},
            note = {{\copyright} Springer Nature Switzerland AG 2020},
       booktitle = {Medical Image Understanding and Analysis: 24th Annual Conference, MIUA 2020, Oxford, UK, July 15-17, 2020, Proceedings},
           title = {A machine learning approach for Colles' fracture treatment diagnosis},
         address = {Cham},
       publisher = {Springer},
            year = {2020},
             doi = {10.1007/978-3-030-52791-4\_25},
           pages = {319--330},
        keywords = {Fracture; Radiography; Feature analysis; Random forest},
             url = {https://openaccess.city.ac.uk/id/eprint/25605/}
}

%
%
%
@inproceedings{KR2020-90,
    title     = {{Neuro-Symbolic Probabilistic Argumentation Machines}},
    author    = {Riveret, Regis and Tran, Son and d'Avila Garcez, Artur},
    booktitle = {{Proceedings of the 17th International Conference on Principles of Knowledge Representation and Reasoning}},
    pages     = {871--881},
    year      = {2020},
    month     = {9},
    doi       = {10.24963/kr.2020/90},
    url       = {https://doi.org/10.24963/kr.2020/90},
  }
  
%
% Explainability, shortcommings of LSTM's for time series, approaches to address
%
@misc{philps2019making,
      title={Making Good on LSTMs' Unfulfilled Promise}, 
      author={Daniel Philps and Artur d'Avila Garcez and Tillman Weyde},
      year={2019},
      eprint={1911.04489},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

%
% Long-term financial investment, explainability
%
@misc{philps2019continual,
      title={Continual Learning Augmented Investment Decisions}, 
      author={Daniel Philps and Tillman Weyde and Artur d'Avila Garcez and Roy Batchelor},
      year={2019},
      eprint={1812.02340},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

%
% Semantic Image Interpretation
%
@inproceedings{city19151,
           month = {August},
          author = {I. Donadello and L. Serafini and A. S. d'Avila Garcez},
            note = {{\copyright} IJCAI, 2017. http://www.ijcai.org/},
       booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence},
           title = {Logic tensor networks for semantic image interpretation},
         address = {California, USA},
       publisher = {IJCAI},
            year = {2017},
         journal = {IJCAI International Joint Conference on Artificial Intelligence},
           pages = {1596--1602},
        keywords = {Machine Learning: Knowledge-based Learning; Robotics and Vision: Vision and Perception; Uncertainty in AI},
             url = {https://openaccess.city.ac.uk/id/eprint/19151/},
        abstract = {Semantic Image Interpretation (SII) is the task of extracting structured semantic descriptions from images. It is widely agreed that the combined use of visual data and background knowledge is of great importance for SII. Recently, Statistical Relational Learning (SRL) approaches have been developed for reasoning under uncertainty and learning in the presence of data and rich knowledge. Logic Tensor Networks (LTNs) are a SRL framework which integrates neural networks with first-order fuzzy logic to allow (i) efficient learning from noisy data in the presence of logical constraints, and (ii) reasoning with logical formulas describing general properties of the data. In this paper, we develop and apply LTNs to two of the main tasks of SII, namely, the classification of an image's bounding boxes and the detection of the relevant part-of relations between objects. To the best of our knowledge, this is the first successful application of SRL to such SII tasks. The proposed approach is evaluated on a standard image processing benchmark. Experiments show that background knowledge in the form of logical constraints can improve the performance of purely data-driven approaches, including the state-of-theart Fast Region-based Convolutional Neural Networks (Fast R-CNN). Moreover, we show that the use of logical background knowledge adds robustness to the learning system when errors are present in the labels of the training data.}
}

%
% RNNs and explainability
%
@INPROCEEDINGS{7966173,
  author={Russell, Arthur Jack and Benetos, Emmanouil and d'Avila Garcez, Artur},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)}, 
  title={On the memory properties of recurrent neural models}, 
  year={2017},
  volume={},
  number={},
  pages={2596-2603},
  doi={10.1109/IJCNN.2017.7966173}
}

%
%
%
@inproceedings{10.1145/3019612.3019642,
author = {Serafini, Luciano and Donadello, Ivan and Garcez, Artur d'Avila},
title = {Learning and Reasoning in Logic Tensor Networks: Theory and Application to Semantic Image Interpretation},
year = {2017},
isbn = {9781450344869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3019612.3019642},
doi = {10.1145/3019612.3019642},
abstract = {This paper presents a revision of Real Logic and its implementation with Logic Tensor
Networks and its application to Semantic Image Interpretation. Real Logic is a framework
where learning from numerical data and logical reasoning are integrated using first
order logic syntax. The symbols of the signature of Real Logic are interpreted in
the data-space, i.e, on the domain of real numbers. The integration of learning and
reasoning obtained in Real Logic allows us to formalize learning as approximate satisfiability
in the presence of logical constraints, and to perform inference on symbolic and numerical
data. After introducing a refined version of the formalism, we describe its implementation
into Logic Tensor Networks which uses deep learning within Google's TensorFlow™. We
evaluate LTN on the task of classifying objects and their parts in images, where we
combine state-of-the-art-object detectors with a part-of ontology. LTN outperforms
the state-of-the-art on object classification, and improves the performances on part-of
relation detection with respect to a rule-based baseline.},
booktitle = {Proceedings of the Symposium on Applied Computing},
pages = {125–130},
numpages = {6},
keywords = {learning with logical constraints, logic and neural networks},
location = {Marrakech, Morocco},
series = {SAC '17}
}

%
%  Knowledge extraction, knowledge representation of RBM
%
@inproceedings{inproceedings,
author = {Odense, Simon and Garcez, Artur},
year = {2017},
month = {10},
pages = {120-127},
title = {Extracting M of N Rules from Restricted Boltzmann Machines},
isbn = {978-3-319-68611-0},
doi = {10.1007/978-3-319-68612-7_14}
}

%
% 
%
@INPROCEEDINGS{7727536,  author={Tran, Son N. and Garcez, Artur d'Avila},  booktitle={2016 International Joint Conference on Neural Networks (IJCNN)},   title={Adaptive Transferred-profile Likelihood Learning},   year={2016},  volume={},  number={},  pages={2687-2692},  doi={10.1109/IJCNN.2016.7727536}}

%
%
%
@article{city16484,
          volume = {1773},
           month = {December},
          author = {S. Sarkar and T. Weyde and A. Garcez and G. G. Slabaugh and S. Dragicevic and C. Percy},
            note = {Copyright {\copyright} 2016 for this paper by its authors. Copying permitted for private and academic purposes. 

Proceedings of the NIPS Workshop on Cognitive Computation: Integrating neural and symbolic approaches (CoCo 2016), Barcelona, Spain, December 9, 2016.},
       booktitle = {NIPS Workshop on Cognitive Computation: Integrating neural and symbolic approaches (CoCo 2016)},
           title = {Accuracy and interpretability trade-offs in machine learning applied to safer gambling},
       publisher = {CEUR Workshop Proceedings},
            year = {2016},
         journal = {CEUR Workshop Proceedings},
             url = {https://openaccess.city.ac.uk/id/eprint/16484/},
        abstract = {Responsible gambling is an area of research and industry which seeks to understand the pathways to harm from gambling and implement programmes to reduce or prevent harm that gambling might cause. There is a growing body of research that has used gambling behavioural data to model and predict harmful gambling, and the industry is showing increasing interest in technologies that can help gambling operators to better predict harm and prevent it through appropriate interventions. However, industry surveys and feedback clearly indicate that in order to enable wider adoption of such data-driven methods, industry and policy makers require a greater understanding of how machine learning methods make these predictions. In this paper, we make use of the TREPAN algorithm for extracting decision trees from Neural Networks and Random Forests. We present the first comparative evaluation of predictive performance and tree properties for extracted trees, which is also the first comparative evaluation of knowledge extraction for safer gambling. Results indicate that TREPAN extracts better performing trees than direct learning of decision trees from the data. Overall, trees extracted with TREPAN from different models offer a good compromise between prediction accuracy and interpretability. TREPAN can produce decision trees with extended tests rules of different forms, so that interpretability depends on multiple factors. We present detailed results and a discussion of the trade-offs with regard to performance and interpretability and use in the gambling industry.}
}

%
%
%
@article{city16483,
          volume = {285},
          author = {C. Percy and A. Garcez and S. Dragicevic and M. V. M. Fran{\c c}a and G. G. Slabaugh and T. Weyde},
            note = {ECAI 2016: 22nd European Conference on Artificial Intelligence.
{\copyright} 2016 The Authors and IOS Press},
           title = {The Need for Knowledge Extraction: Understanding Harmful Gambling Behavior with Neural Networks},
       publisher = {IOS Press},
            year = {2016},
         journal = {Frontiers in Artificial Intelligence and Applications},
             doi = {10.3233/978-1-61499-672-9-974},
           pages = {974--981},
        keywords = {Neural Networks; Knowledge Extraction; Gambling; Problem Gambling},
             url = {https://openaccess.city.ac.uk/id/eprint/16483/},
        abstract = {Responsible gambling is a field of study that involves supporting gamblers so as to reduce the harm that their gambling activity might cause. Recently in the literature, machine learning algorithms have been introduced as a way to predict potentially harmful gambling based on patterns of gambling behavior, such as trends in amounts wagered and the time spent gambling. In this paper, neural network models are analyzed to help predict the outcome of a partial proxy for harmful gambling behavior: when a gambler ?self-excludes?, requesting a gambling operator to prevent them from accessing gambling opportunities. Drawing on survey and interview insights from industry and public officials as to the importance of interpretability, a variant of the knowledge extraction algorithm TREPAN is proposed which can produce compact, human-readable logic rules efficiently, given a neural network trained on gambling data. To the best of our knowledge, this paper reports the first industrial-strength application of knowledge extraction from neural networks, which otherwise are black-boxes unable to provide the explanatory insights which are crucially required in this area of application. We show that through knowledge extraction one can explore and validate the kinds of behavioral and demographic profiles that best predict self-exclusion, while developing a machine learning approach with greater potential for adoption by industry and treatment providers. Experimental results reported in this paper indicate that the rules extracted can achieve high fidelity to the trained neural network while maintaining competitive accuracy and providing useful insight to domain experts in responsible gambling.}
}

%
%
%
@inproceedings{DBLP:conf/nesy/YilmazGS16,
  author    = {{\"{O}}zg{\"{u}}r Yilmaz and
               Artur S. d'Avila Garcez and
               Daniel L. Silver},
  editor    = {Tarek R. Besold and
               Lu{\'{\i}}s C. Lamb and
               Luciano Serafini and
               Whitney Tabor},
  title     = {A Proposal for Common Dataset in Neural-Symbolic Reasoning Studies},
  booktitle = {Proceedings of the 11th International Workshop on Neural-Symbolic
               Learning and Reasoning (NeSy'16) co-located with the Joint Multi-Conference
               on Human-Level Artificial Intelligence {(HLAI} 2016), New York City,
               NY, USA, July 16-17, 2016},
  series    = {{CEUR} Workshop Proceedings},
  volume    = {1768},
  publisher = {CEUR-WS.org},
  year      = {2016},
  url       = {http://ceur-ws.org/Vol-1768/NESY16\_paper5.pdf},
  timestamp = {Wed, 12 Feb 2020 16:44:20 +0100},
  biburl    = {https://dblp.org/rec/conf/nesy/YilmazGS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%
%
%
@misc{serafini2016logic,
      title={Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge}, 
      author={Luciano Serafini and Artur d'Avila Garcez},
      year={2016},
      eprint={1606.04422},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

%
% Discriminative learning and inference in the Recurrent Temporal RBM for melody modelling
%
@INPROCEEDINGS{7280691,  author={Cherla, Srikanth and Tran, Son N. and Garcez, Artur d'Avila and Weyde, Tillman},  booktitle={2015 International Joint Conference on Neural Networks (IJCNN)},   title={Discriminative learning and inference in the Recurrent Temporal RBM for melody modelling},   year={2015},  volume={},  number={},  pages={1-8},  doi={10.1109/IJCNN.2015.7280691}}

%
% Efficient representation ranking for transfer learning
%
@INPROCEEDINGS{7280454,  author={Tran, Son N. and Garcez, Artur d'Avila},  booktitle={2015 International Joint Conference on Neural Networks (IJCNN)},   title={Efficient representation ranking for transfer learning},   year={2015},  volume={},  number={},  pages={1-8},  doi={10.1109/IJCNN.2015.7280454}}

%
% A Hybrid Recurrent Neural Network For Music Transcription
% https://arxiv.org/pdf/1411.1623.pdf
@misc{sigtia2014hybrid,
      title={A Hybrid Recurrent Neural Network For Music Transcription}, 
      author={Siddharth Sigtia and Emmanouil Benetos and Nicolas Boulanger-Lewandowski and Tillman Weyde and Artur S. d'Avila Garcez and Simon Dixon},
      year={2014},
      eprint={1411.1623},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

%
% Neural-symbolic learning and reasoning: contributions and challenges
%
@inproceedings{garcez2015neural,
  title={Neural-symbolic learning and reasoning: contributions and challenges},
  author={Garcez, Artur d'Avila and Besold, Tarek R and De Raedt, Luc and F{\"o}ldiak, Peter and Hitzler, Pascal and Icard, Thomas and K{\"u}hnberger, Kai-Uwe and Lamb, Luis C and Miikkulainen, Risto and Silver, Daniel L},
  booktitle={2015 AAAI Spring Symposium Series},
  year={2015}
}

%
% Relational learning can be described as the task of learn-
% ing a first-order logic theory from examples (Dˇzeroski and
%Lavraˇc 2001; De Raedt 2008). Differently from proposi-
%tional learning, relational learning does not use a set of at-
%tributes and values. Instead, it is based on objects and rela-
%tions among objects, which are represented by constants and
%predicates, respectively. This enables a range of applications
%of machine learning, for example in bioinformatics, graph
%mining and link analysis in social networks, serious games,
%and responsible gambling
%
@inproceedings{francca2015neural,
  title={Neural relational learning through semi-propositionalization of bottom clauses},
  author={Fran{\c{c}}a, Manoel Vitor Macedo and Zaverucha, Gerson and Garcez, Artur S d'Avila},
  booktitle={2015 AAAI Spring Symposium Series},
  year={2015}
}

%
%
%
@article{Perotti_2014,
   title={Runtime Verification Through Forward Chaining},
   volume={169},
   ISSN={2075-2180},
   url={http://dx.doi.org/10.4204/EPTCS.169.8},
   DOI={10.4204/eptcs.169.8},
   journal={Electronic Proceedings in Theoretical Computer Science},
   publisher={Open Publishing Association},
   author={Perotti, Alan and Boella, Guido and d’ Avila Garcez, Artur},
   year={2014},
   month={Dec},
   pages={68–81}
}

%
% In this paper, a novel methodology is proposed for the
% extraction of relational knowledge from neural networks 
%
@inproceedings{francca2015relational,
  title={Relational knowledge extraction from neural networks},
  author={Fran{\c{c}}a, Manoel Vitor Macedo and Garcez, Artur S d'Avila and Zaverucha, Gerson},
  booktitle={CoCo@ NIPS},
  year={2015}
}
%
% Learning motion-difference features using Gaussian restricted Boltzmann machines for efficient human action recognition
% Leaning motion through saliency maps, remove background use RBM to annotate ?
% proposed a new approach to learn spatio-temporal features using a difference measure between frames in a video sequence, called  motion-difference, and applying Gaussian RBMs.

@inproceedings{tran2014learning,
  title={Learning motion-difference features using Gaussian restricted Boltzmann machines for efficient human action recognition},
  author={Tran, Son N and Benetos, Emmanouil and Garcez, Artur d'Avila},
  booktitle={2014 International Joint Conference on Neural Networks (IJCNN)},
  pages={2123--2129},
  year={2014},
  organization={IEEE}
}


%%%%%%%%%%%%%
%% METHODS %%
%%%%%%%%%%%%%

% SIMULATORS

% AirSim
@inproceedings{airsim2017fsr,
  author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor},
  title = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles},
  year = {2017},
  booktitle = {Field and Service Robotics},
  eprint = {arXiv:1705.05065},
  url = {https://arxiv.org/abs/1705.05065}
}

%%%%%%%%%%%%%
%% RESULTS %%
%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%
%% EVALUATION %%
%%%%%%%%%%%%%%%%